{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NacliNaclo/NPL/blob/main/05_Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auM3jLkGYHk5"
      },
      "source": [
        "Word Embeddings\n",
        "\n",
        "In this session we will make use of Word2Vec to learn distributed representations of words based on the context within which they appear in sentences. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPtKB1FNYHlH"
      },
      "source": [
        "## Learning word embeddings\n",
        "\n",
        "We'll first try to learn word embeddings using the Word2Vec implementation provided by the gensim package. \n",
        "- Information on gensim's word2vec implementation is available here: https://radimrehurek.com/gensim/models/word2vec.html\n",
        "- First install the package using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmJqt2NRYHlH",
        "outputId": "00cdf959-bb46-4ec9-f319-0d6e04bbaac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.9/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from gensim) (6.3.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.9/dist-packages (from gensim) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdrV0qU6YHlH"
      },
      "source": [
        "We will build a Word2Vec embedding using the 20 Newsgroup data:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "technique to build embeddings \n",
        "FAST TWXT MODEL AND WORD2VEC model are trained in the same way"
      ],
      "metadata": {
        "id": "YG5A7lkQ7zsA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v_erNR7XIrDh"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "dataset_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "dataset_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTTluJ3TYHlH"
      },
      "source": [
        "In order to train Word2Vec on the data we first need to convert it to the right format. \n",
        "- For training Word2Vec, it is usual to **separate data into individual sentences** and then tokenize those sentences separately\n",
        "- So let's use regular expressions to remove the end-of-line characters from each document and then split the documents into sentences using a regular expression that looks for question marks, exclamation marks, and periods, followed by a space: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jCPB46UYHlH",
        "outputId": "0f8ad2fe-67f0-4222-b8ce-7d9f76ba7cd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['I was wondering if anyone out there could enlighten me on this car I saw the other day',\n",
              "  'It was a 2-door sports car, looked to be from the late 60s/ early 70s',\n",
              "  'It was called a Bricklin',\n",
              "  'The doors were really small',\n",
              "  'In addition, the front bumper was separate from the rest of the body',\n",
              "  'This is  all I know',\n",
              "  'If anyone can tellme a model name, engine specs, years of production, where this car is made, history, or whatever info you have on this funky looking car, please e-mail.'],\n",
              " ['A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll',\n",
              "  'Please send a brief message detailing your experiences with the procedure',\n",
              "  'Top speed attained, CPU rated speed, add on cards and adapters, heat sinks, hour of usage per day, floppy disk functionality with 800 and 1.4 m floppies are especially requested',\n",
              "  \" I will be summarizing in the next two days, so please add to the network knowledge base if you have done the clock upgrade and haven't answered this poll\",\n",
              "  'Thanks.']]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# we use regular expression to remove useless words\n",
        "\n",
        "# remove newline characters\n",
        "docs = [re.sub('\\n', ' ', doc) for doc in dataset_train.data]\n",
        "# remove email addresses\n",
        "docs = [re.sub('[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', '', doc) for doc in docs]\n",
        "# split sentences \n",
        "sentences = [re.split('[?!.]\\s', doc) for doc in docs] #we serach for specific punctuaction in order to idnetify the end of a sentences. \n",
        "# we start from a document so fr this reason we want to obtain the sentences \n",
        "sentences[:2]\n",
        "\n",
        "#each list contains the different sentences in a document. we have aslo an external list that contains the all docuemnts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIucFhmVYHlI"
      },
      "source": [
        "Above, we've printed out the first two documents, which have been split into arrays of sentences. \n",
        "- We'll need to flatten the structure into one big array of sentences (remove the distinction between documents) before providing it to Word2Vec. \n",
        "- We can do that using the flatten command from the pandas library:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB2YTCX1YHlI",
        "outputId": "47989c21-daac-4f57-e75a-f830fd76bb29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I was wondering if anyone out there could enlighten me on this car I saw the other day',\n",
              " 'It was a 2-door sports car, looked to be from the late 60s/ early 70s',\n",
              " 'It was called a Bricklin',\n",
              " 'The doors were really small',\n",
              " 'In addition, the front bumper was separate from the rest of the body',\n",
              " 'This is  all I know',\n",
              " 'If anyone can tellme a model name, engine specs, years of production, where this car is made, history, or whatever info you have on this funky looking car, please e-mail.',\n",
              " 'A fair number of brave souls who upgraded their SI clock oscillator have shared their experiences for this poll',\n",
              " 'Please send a brief message detailing your experiences with the procedure',\n",
              " 'Top speed attained, CPU rated speed, add on cards and adapters, heat sinks, hour of usage per day, floppy disk functionality with 800 and 1.4 m floppies are especially requested',\n",
              " \" I will be summarizing in the next two days, so please add to the network knowledge base if you have done the clock upgrade and haven't answered this poll\",\n",
              " 'Thanks.',\n",
              " 'well folks, my mac plus finally gave up the ghost this weekend after starting life as a 512k way back in 1985',\n",
              " \" sooo, i'm in the market for a new machine a bit sooner than i intended to be..\",\n",
              " \" i'm looking into picking up a powerbook 160 or maybe 180 and have a bunch of questions that (hopefully) somebody can answer:  * does anybody know any dirt on when the next round of powerbook introductions are expected\",\n",
              " ' i\\'d heard the 185c was supposed to make an appearence \"this summer\" but haven\\'t heard anymore on it - and since i don\\'t have access to macleak, i was wondering if anybody out there had more info..',\n",
              " \" * has anybody heard rumors about price drops to the powerbook line like the ones the duo's just went through recently\",\n",
              " \" * what's the impression of the display on the 180\",\n",
              " ' i could probably swing a 180 if i got the 80Mb disk rather than the 120, but i don\\'t really have a feel for how much \"better\" the display is (yea, it looks great in the store, but is that all \"wow\" or is it really that good?)',\n",
              " ' could i solicit some opinions of people who use the 160 and 180 day-to-day on if its worth taking the disk size and money hit to get the active display']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from pandas.core.common import flatten\n",
        "#we want only a list a list of  string.\n",
        "\n",
        "sentences = list(flatten(sentences))\n",
        "sentences[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAQ0LlmEYHlI"
      },
      "source": [
        "Now we can proceed to do some cleaning of the data: \n",
        "- remove non-letter characters from each sentence \n",
        "- lowercase \n",
        "- tokenize the sentences based on whitespace\n",
        "- remove any sentence with length less than 2 since it won't be useful for training Word2Vec. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgpm3IvQYHlI",
        "outputId": "04dff620-aaaa-449b-ec3c-c553f3e86356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'i', 'saw', 'the', 'other', 'day']\n",
            "['it', 'was', 'a', '2', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', '60s', 'early', '70s']\n",
            "['it', 'was', 'called', 'a', 'bricklin']\n",
            "['the', 'doors', 'were', 'really', 'small']\n",
            "['in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body']\n",
            "['this', 'is', 'all', 'i', 'know']\n",
            "['if', 'anyone', 'can', 'tellme', 'a', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'e', 'mail']\n",
            "['a', 'fair', 'number', 'of', 'brave', 'souls', 'who', 'upgraded', 'their', 'si', 'clock', 'oscillator', 'have', 'shared', 'their', 'experiences', 'for', 'this', 'poll']\n",
            "['please', 'send', 'a', 'brief', 'message', 'detailing', 'your', 'experiences', 'with', 'the', 'procedure']\n",
            "['top', 'speed', 'attained', 'cpu', 'rated', 'speed', 'add', 'on', 'cards', 'and', 'adapters', 'heat', 'sinks', 'hour', 'of', 'usage', 'per', 'day', 'floppy', 'disk', 'functionality', 'with', '800', 'and', '1', '4', 'm', 'floppies', 'are', 'especially', 'requested']\n"
          ]
        }
      ],
      "source": [
        "tokenized_sentences = [re.sub('\\W', ' ', sentence).lower().split() for sentence in sentences] #remove whatever is a non alpha numerical character\n",
        "# remove sentences that are only 1 word long\n",
        "tokenized_sentences = [sentence for sentence in tokenized_sentences if len(sentence) > 1]\n",
        "\n",
        "#we remove all the capital leacture\n",
        "#after cleaning, we take the single words\n",
        "\n",
        "for sentence in tokenized_sentences[:10]:\n",
        "    print(sentence)\n",
        "#in the inner list we have the different words in each sentences contained in a  single document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xYG3RKRYHlI"
      },
      "source": [
        "Finally we have the data in the right format for training Word2Vec, so we can provide it to the algorithm. For parameters, we set: \n",
        "- the embedding size to be 30,\n",
        "- the minimum count for any vocabulary term to be 5\n",
        "- the size of the context window to 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fXolbjAXYHlJ"
      },
      "outputs": [],
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "model = Word2Vec(tokenized_sentences, vector_size=30, min_count=5, window=10) #we decide the size of the enbeddings, and the context windows to create this representation\n",
        "\n",
        "#w1 w2 w3 w4 (half of the windows to the left and half on the right)\n",
        "#w2 <--> w1,w3\n",
        "#w3 <--> w2,w4\n",
        "#w1 <--> w2\n",
        "#w4 <--> w3\n",
        "#both can be the input and the output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BP16EM3YHlJ"
      },
      "source": [
        "Let's see how big the vocabulary is that Word2Vec ended up using, i.e. how many word vectors did it learn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7ZYKyxcYHlJ",
        "outputId": "df0f7db9-c552-404c-d6e4-73e32ce2babb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22069"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "len(model.wv) #we look at the vocabulary we have exctracted "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHRbIkEYYHlJ"
      },
      "source": [
        "## Inspecting embeddings and finding similar words\n",
        "\n",
        "Now that we have a word2vec model trained, what can we do with it?\n",
        "- Let's print out one of the vectors to see what it looks like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XJtGX3YYHlJ",
        "outputId": "ce635f5f-99d2-4c7f-8733-11e1e281a21a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.5736664 ,  0.1807864 ,  3.0204968 , -1.0520675 ,  0.19522382,\n",
              "        0.06506994, -1.9525828 , -1.226235  ,  0.9067324 , -0.41677034,\n",
              "        0.5631861 ,  2.9364316 ,  1.4069711 , -0.46517557,  0.94183236,\n",
              "       -2.9987383 ,  3.7066686 ,  1.3071213 , -2.0785937 , -0.8308649 ,\n",
              "       -0.3676263 ,  0.27375138,  0.31687638, -1.759956  , -0.9749201 ,\n",
              "       -1.5826696 ,  0.37159052,  0.04090898,  3.478853  ,  2.3960354 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "term = 'car'\n",
        "model.wv[term] #we have an array that represent the embedding representation vector\n",
        "#positive and negative values so space is in all the part (not in a single quadrante)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAcJZJmyYHlJ"
      },
      "source": [
        "Unlike LDA's document topic vector, this one has both positive and negative values.\n",
        "\n",
        "We could now use the model to compute similarities between terms based on their cosine distance in the embedding space.\n",
        "- Try modifying the terms below to see what their closest neighbouring terms are: \n",
        "  - Some good terms to try are: hockey, mouse, god, microsoft, clinton, bush, etc.\n",
        "  - (If yuo see an error, that is because the term you chose is not in the dictionary.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej6ij-9-YHlK",
        "outputId": "af75da6e-1251-4764-8d62-85ab2c67b0ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('president', 0.8820016980171204),\n",
              " ('administration', 0.8569158315658569),\n",
              " ('initiative', 0.799329936504364),\n",
              " ('bush', 0.7598156332969666),\n",
              " ('policy', 0.7584185004234314),\n",
              " ('justice', 0.7478051781654358),\n",
              " ('official', 0.7415000200271606),\n",
              " ('decision', 0.7334609031677246),\n",
              " ('authority', 0.7310336828231812),\n",
              " ('hail', 0.7294169068336487)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#term = 'gun'\n",
        "#term = 'microsoft'\n",
        "term ='clinton'\n",
        "model.wv.most_similar(term)\n",
        "#we are searching the very similar words with repsecet the input (close vector in the space)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldnMBi7qYHlK"
      },
      "source": [
        "Do the similar terms agree with your intuition?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Su5jmKYHlK"
      },
      "source": [
        "## Visualising the embedding vectors using t-SNE\n",
        "\n",
        "We'll now visualise some of the word vectors in a 3 dimensional space using t-SNE.\n",
        "\n",
        "The vocabulary of word vectors is quite large (around 25,000). Giving them all to t-SNE will cause it to take far too long to converge.\n",
        "- So let's first choose a random subset of 500 terms to show:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3GC2wXgYHlK",
        "outputId": "c5650df2-7934-4a4b-df1f-9f21beb1afc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['filters', 'cream', 'ceremonies', 'hesketh', 'mandated', '1950', 'insists', 'wingate', 'staunch', 'graduated', 'caratzas', 'ajwmw', 'former', '0l', 'wailing', '602', 'toyota', 'politics', 'frame', '30pm', 'tray', 'reminded', 'rouge', '1959', 'treaties', 'salah', 'cathy', 'paganism', 'msfc', 'ariv', 'labs', 'mcintyre', 'gr', '5a', 'des', 'offender', 'aum', 'abide', 'columbus', 'geostationary', 'babylon', 'directly', 'leaves', 'strengths', 'confined', 'roderick', 'flawed', 'abusive', 'insofar', 'npr', '986', 'remarkably', 'tables', 'thu', 'ntr', 'overwhelmed', 'expos', 'hci', 'gca', 'hints', 'credibility', 'upgrade', 'herpesvirus', 'mahaffey', 'se1', 'smoothing', 'wha', 'x74', 'ngt', 'lord', '284', 'gift', 'radically', 'aclu', 'regards', '654', 'revenge', 'hamilton', '248', 'pregnant', 'turk', 'sixties', '501', 'passport', 'ohm', 'pub', 'l8', 'legend', 'breakdown', 'misunderstand', 'politicians', 'foia', '882', 'slaughter', 'occupation', 'tail', 'shocking', '305', '6ej', 'grad', 'havn', 'spanking', 'coli', 'explosive', 'occurred', 'comparable', 'denoted', 'pclk', 'hiking', 'removal', 'excuse', 'responds', 'mcnulty', 'tricks', 'pposition', 'academics', 'powerless', 'association', '75di', 'deficiencies', 'br_', 'boarding', 'i2j', 'direct', 'depend', 'bounce', 'infra', 'southy', 'owned', 'rockefeller', 'thriving', 'another', 'godly', 'nagarno', 'dwi', 'circumference', 'irenaeus', 'stationary', 'follow', 'burrows', 'removed', 'j75u', 'collision', 'ingredients', '314', 'hunting', 'sheffield', 'd2_', 'january', 'houston', 'alley', '1033', 'lt', 'nkhf', 'utrecht', 'book', 'hite', 'supervisor', 'equ', 'engaging', 'isaiah', 'card', 'mds', 'rip', 'bcopy', '275', 'jdr', 'approach', 'qs4u', 'wl', 'kernel', '15am', 'blindness', 'supernatural', 'win3', 'pathway', 'sinking', 'seventh', 'rz350', 'supported', '805', 'cornering', 'zq', '6w8', 'comma', 'ops', 'pity', 'woofers', 'nowadays', 'powering', 'outdated', 'oxide', 'conforms', 'malaria', 'racism', 'gopher', 'membrane', 'umanitoba', '4l', 'gender', '_xmbctidtocsid', '885', 'feingold', '8v', 'mckay', 'mg', 'modelling', 'athena', 'county', 'watches', 'allow', 'abdullah', 'interactively', 'meet', 'parsing', '801', 'rename', 'acknowledge', 'phones', '139', 'prone', '2215', 'invading', 'batter', '13qs', 'hoax', 'plague', 'shell', 'more_auths', 'duc', 'widely', 'obstruction', 'brandt', '6d', 'pundits', 'cuts', 'appliances', 'mw3p', 'trust', 'spectacular', 'lakes', 'suddenly', 'mohammad', 'ld_run_path', 'silicone', 'page', 'shameful', 'specter', '450', 'chiggers', 'accomodation', 'rpc', 'graves', '85mb', 'okidata', '470', 'moonroof', '1rk', 'implemented', 'sunset', 'cyberspace', 'explosives', 'spain', 'basis', 'mpg', 'sim', 'pediatric', 'jy', '217', 'buddhism', 'unizh', 'mqvg', 'shot', 'avenues', '1069', 'jayne', 'bigot', '597', 'stock', 'printout', '737', 'justifications', 'whose', 'hungry', 'microsoft', 'kidding', 'vii', '902', 'stu', 'also', 'element', '324', 'b9r', 'mz', 'symantec', 'output_entry', 'milt', 'daytona', 'embassy', 'intermittent', 'ankle', 'z4j', 'onur', 'values', 'roles', 'jumbo', 'establishes', 'lunar', 'atrophy', 'assaults', 'acidophilus', 'boycott', '104', 'economically', 'witch', 'violated', 'fli', 'eternal', 'plot', 'chairman', 'hobby', 'august', 'urgent', 'vtz', 'laughed', 'watson', 'crossposting', 'dominate', 'mouse', 'wil', 'prediction', 'israelites', 'hid', '74f', '7423', 'decwrl', 'compromised', 'usaf', 'bitmap', 'keepers', 'keypress', 'supportive', 'ilhan', 'poly', '32k', 'hobbyists', 'sentences', 'informed', 'prototype', 'genuine', 'proscribed', 'notify', 'blatantly', 'finns', '45s', 'santiago', '10k', 'prom', '5200', 'magazine', 'programmers', 'during', 'condem', '218', 'trenches', '827', 'handedness', 'pioneer', 'reuss', 'respond', 'enzyme', 'qumran', 'cited', '252', 'surgeons', 'conquest', 'cato', 'noon', 'guests', 'ache', '152', 'block', 'respective', 'dv', 'ghjn', 'shelf', 'pushing', 'i2d', 'significant', 'fail', 'seas', 'players', 'ratushny', 'individuals', 'feeling', 'finger', 'drug', 'lutheran', 'bichette', 'impose', 'guarded', 'xwocx', 'wizard', 'rollers', 'foil', 'derivation', 'momentum', 'fynv', 'images', '560', '27', 'covington', 'bullock', 'courtesy', 'anecdotes', 'wasps', 'residence', 'mysteries', 'yup', 'kellog', 'generations', 'restricted', '989', 'purely', 'diffie', 'stanford', 'neighbors', 'west', 'reconciliation', 'rifles', 'rix', 'bamford', 'accusing', 'penetrate', 'experiencing', 'configured', 'ibm', 'parcplace', 'affirmed', 'lvc', 'struck', 'usr0', 'vessels', 'northern', 'exhausted', '642', 'zal', 'bully', 'interfacing', 'colors', 'riddle', 'heap', 'inflicting', 'aleppo', 'context', 'nor', 'armored', 'deborah', 'helium', 'batters', '8514', 'wb', 'donation', 'graphic', 'bxltq6', 'armour', 'ready', 'male', 'shortly', '1800', 'conspiracy', 'down', 'coordination', 'wittgenstein', 'roush', 'idea', 'somehow', 'voltage', 'late', '1j', 'command', 'organization', 'sunk', '1h', 'extortion', 'xtaddeventhandler', 'mistakenly', 'retreive', 'racks', 'buffalo', 'unipalm', 'njd', '8mb', 'rachel', '61d', 'berman', 'gosselin', '3k', 'plymouth', '9f9f9f9f']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# we need a reduction dimensianal technique in order to represent and show the different word representation\n",
        "\n",
        "sample = random.sample(list(model.wv.key_to_index), 500)\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb51ZnSpYHlK"
      },
      "source": [
        "Now we'll get the word vectors for the sampled terms:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdIlwUjaYHlK",
        "outputId": "cfb9090f-2193-440f-e23d-ae6fb17f1ebf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.59136999e-01, -7.14533508e-01,  2.78420657e-01, ...,\n",
              "         8.14627469e-01, -6.02724310e-03, -2.50621080e-01],\n",
              "       [-1.28274396e-01, -1.27736568e-01,  2.68556505e-01, ...,\n",
              "         1.02547415e-01,  8.52862522e-02, -3.14902604e-01],\n",
              "       [-1.04257740e-01,  5.34909256e-02,  1.62880972e-01, ...,\n",
              "        -6.03582896e-02, -5.25821894e-02, -9.52422172e-02],\n",
              "       ...,\n",
              "       [-3.46708298e-01, -1.11891663e+00,  2.59293377e-01, ...,\n",
              "         8.08958828e-01, -2.21584260e-01, -9.40158486e-01],\n",
              "       [-1.63003746e-02, -2.58769214e-01,  1.70087025e-01, ...,\n",
              "         3.30321997e-01,  6.05002195e-02, -4.57114756e-01],\n",
              "       [ 1.18937334e-02, -4.20512371e-02,  9.57857817e-02, ...,\n",
              "        -6.63055480e-03, -4.76410314e-02,  4.75078792e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "word_vectors = model.wv[sample]\n",
        "word_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPKDpTt9YHlK"
      },
      "source": [
        "And we'll provide the vectors to TSNE to fit a model and transform the data to 3 dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "TdSwKpggYHlK"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=3, n_iter=2000) #projection in a 3 dimensions\n",
        "tsne_embedding = tsne.fit_transform(word_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWDA5VAFYHlL"
      },
      "source": [
        "Now transform the data into 3 columns (for x, y, and z):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "F-ubEgoDYHlL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "x, y, z = np.transpose(tsne_embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RQtluK0YHlL"
      },
      "source": [
        "And generate the 3d plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTIn4dEW4-8r",
        "outputId": "2417c46a-6bb6-4106-ec48-b7a245dda7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (5.13.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly) (8.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Addk422Dt_IW",
        "outputId": "dce015e6-5df2-43a9-cf67-77fbaa5cc3e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"0e3c44f3-523c-4a79-ad86-c27cb4b29f49\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0e3c44f3-523c-4a79-ad86-c27cb4b29f49\")) {                    Plotly.newPlot(                        \"0e3c44f3-523c-4a79-ad86-c27cb4b29f49\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>z=%{z}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"line\":{\"width\":2},\"size\":3},\"mode\":\"markers\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"x\":[-5.288376331329346,-7.399438381195068,3.143462896347046,11.211236000061035,-11.905241966247559,-8.192967414855957,-8.915616035461426,8.269021034240723,0.6238380670547485,9.979178428649902,7.9605393409729,31.394201278686523,-26.799314498901367,28.418731689453125,-16.08221435546875,-7.450580596923828,10.409594535827637,6.0566182136535645,-1.0221208333969116,1.2604206800460815,-4.637762069702148,-11.505729675292969,12.484148979187012,-18.665451049804688,-0.179735466837883,18.5765438079834,25.356639862060547,-0.18982532620429993,0.7756959199905396,26.01319122314453,-3.9958229064941406,2.471705436706543,10.991164207458496,21.9027156829834,-11.016947746276855,8.300216674804688,38.19407653808594,27.67820167541504,-5.458894729614258,4.114339828491211,-24.614362716674805,-5.978143215179443,-10.487565040588379,5.039451599121094,15.333364486694336,-3.434523344039917,-20.253602981567383,-8.898650169372559,0.8429838418960571,26.020719528198242,12.736211776733398,-17.820377349853516,-4.063958168029785,-4.3155364990234375,18.774024963378906,9.633091926574707,-12.068949699401855,-27.050472259521484,1.9245821237564087,-6.160740375518799,-14.213034629821777,7.130969047546387,34.61437225341797,-5.956613063812256,25.820022583007812,-11.72714900970459,13.473323822021484,20.63051414489746,29.069660186767578,-34.14004898071289,-1.9197895526885986,-23.85382652282715,-12.440592765808105,7.404250621795654,-8.90417766571045,9.655231475830078,0.6680594682693481,-13.269638061523438,6.569542407989502,-21.875425338745117,-12.697641372680664,-0.791601836681366,3.271703004837036,14.40322494506836,2.832347869873047,-6.99981164932251,23.065526962280273,-21.08306884765625,-9.549190521240234,-9.092395782470703,-27.177366256713867,3.9847071170806885,7.253046035766602,-29.115633010864258,-27.12983512878418,-4.359943866729736,-1.013936996459961,-7.555912971496582,21.59099006652832,-5.599700450897217,18.099367141723633,9.278861045837402,-12.038290977478027,-17.90552520751953,-25.50333595275879,-5.415999889373779,22.785982131958008,5.636483192443848,4.119478702545166,-9.280073165893555,-14.8136625289917,-2.5445053577423096,-3.3166253566741943,-0.2401885986328125,-1.649182677268982,-23.648231506347656,9.522090911865234,-24.621599197387695,16.231380462646484,6.815588474273682,19.597511291503906,6.3170247077941895,28.643156051635742,-5.1254496574401855,-11.922690391540527,3.8780651092529297,3.476881742477417,11.651019096374512,-18.715343475341797,-23.903669357299805,8.417810440063477,-26.31454849243164,1.485678791999817,-9.134273529052734,-2.8143556118011475,12.524828910827637,4.914846897125244,9.38978099822998,-3.9955475330352783,-5.702243328094482,-6.531413555145264,16.54492950439453,0.6139834523200989,-8.034163475036621,3.6246836185455322,-11.22579574584961,-7.796806335449219,17.474166870117188,-17.176538467407227,-15.235148429870605,17.247575759887695,22.49347686767578,25.985902786254883,24.669757843017578,11.068037033081055,-27.94687843322754,16.169876098632812,14.612735748291016,1.326439619064331,-13.584102630615234,-24.817378997802734,5.314001083374023,19.32957649230957,-6.654120922088623,30.142671585083008,-6.185067653656006,20.584856033325195,-23.41428565979004,29.15624237060547,32.63324737548828,-4.20383358001709,22.176664352416992,2.140807867050171,-24.075105667114258,3.7895424365997314,14.157355308532715,11.352256774902344,-22.46864891052246,-1.683305263519287,-15.001409530639648,-9.296624183654785,-1.2682331800460815,23.616483688354492,11.980846405029297,5.9747796058654785,-16.42572784423828,-20.453771591186523,18.083131790161133,-0.11302213370800018,18.42504119873047,4.66042947769165,-15.18731689453125,-1.073417067527771,-13.670775413513184,-30.146665573120117,13.995789527893066,-12.728890419006348,3.9593441486358643,21.071895599365234,-20.88743782043457,-4.482439041137695,31.4041748046875,10.69258975982666,19.858577728271484,14.410529136657715,27.058046340942383,-10.525465965270996,-1.9416592121124268,-18.441020965576172,10.409523963928223,-5.49825382232666,-21.003149032592773,2.1118340492248535,-10.853206634521484,6.352779388427734,-3.6502084732055664,2.020737886428833,-26.18421745300293,-12.400371551513672,-1.6126140356063843,-22.30206871032715,10.944583892822266,-25.152687072753906,0.7164562940597534,23.65540313720703,-5.084975242614746,-5.952185153961182,4.215506076812744,5.828792095184326,19.432411193847656,-15.290678977966309,6.659092426300049,18.846811294555664,24.794292449951172,3.3641891479492188,-12.27968978881836,-3.321467161178589,14.583795547485352,-4.898196220397949,1.155658483505249,7.480697154998779,-25.045936584472656,10.315901756286621,30.774690628051758,-8.92960262298584,-10.49384880065918,-25.26485824584961,20.567901611328125,-2.295722246170044,12.56264591217041,7.649804592132568,22.837011337280273,-11.60531234741211,15.719548225402832,9.476757049560547,15.032204627990723,9.74988842010498,24.313243865966797,-12.839303970336914,7.335834503173828,14.33092212677002,-17.601932525634766,-21.590431213378906,-26.197113037109375,14.101357460021973,18.67644500732422,2.6237504482269287,21.70319366455078,0.8367230892181396,-16.271699905395508,1.7326968908309937,33.21561813354492,-20.29159164428711,-5.862856864929199,10.34359073638916,20.719524383544922,13.592041969299316,11.443924903869629,-8.948057174682617,25.546016693115234,9.303414344787598,7.364593982696533,-30.489784240722656,-5.214375019073486,4.1075334548950195,-19.157026290893555,7.816051483154297,11.197277069091797,-8.435648918151855,-12.091907501220703,-17.96162986755371,10.159476280212402,18.68572235107422,24.620370864868164,23.22356605529785,4.292082786560059,4.965687274932861,14.25184154510498,-17.223796844482422,1.2328178882598877,7.363635540008545,29.900461196899414,-15.85638427734375,-12.454596519470215,-12.027226448059082,16.522951126098633,-1.570942759513855,-19.111618041992188,-7.604162216186523,-25.359167098999023,-3.217196464538574,-19.632246017456055,-5.247360706329346,-21.452999114990234,-9.673574447631836,-16.574514389038086,-6.5979695320129395,-30.296445846557617,-6.050792694091797,-18.314666748046875,-9.487361907958984,-17.39890480041504,22.53274917602539,27.97366714477539,-20.5657901763916,-0.0752405971288681,0.5157462358474731,-26.00798988342285,6.067228317260742,17.93413734436035,-4.146212100982666,-9.68578815460205,-8.514561653137207,-11.891645431518555,28.94974136352539,6.788765907287598,-18.202943801879883,-14.908148765563965,0.6386251449584961,9.027124404907227,25.612476348876953,-5.031351089477539,-15.141706466674805,21.049535751342773,4.6875834465026855,-4.899905681610107,-2.0627050399780273,-13.938273429870605,15.151999473571777,-20.837339401245117,3.232391595840454,5.163426876068115,-18.019527435302734,30.626243591308594,15.924195289611816,-2.4542222023010254,-7.579522609710693,28.346633911132812,8.153830528259277,-12.897004127502441,1.1716792583465576,-24.65915298461914,25.4145450592041,12.768796920776367,15.904189109802246,3.9927377700805664,14.38820743560791,3.24302339553833,-18.709428787231445,-7.585240840911865,-8.818005561828613,4.468220233917236,-5.9111409187316895,2.095075845718384,-0.6869710683822632,15.367002487182617,-10.292373657226562,7.230377197265625,-4.376611232757568,-0.014651359990239143,-1.73907470703125,-8.180525779724121,-10.70251178741455,27.93449592590332,22.396272659301758,-3.428601026535034,-4.131734371185303,30.019872665405273,-22.11862564086914,-1.383668303489685,1.5821770429611206,-21.183881759643555,10.44011116027832,-28.85713005065918,-23.924697875976562,-5.019313812255859,-31.795570373535156,-26.41397476196289,7.42741584777832,-14.667665481567383,-5.129004955291748,7.370781898498535,-7.972631454467773,13.516641616821289,4.970751762390137,13.111063957214355,-16.418500900268555,35.13005447387695,-4.507325649261475,6.235208034515381,-13.452784538269043,-6.019515037536621,-22.0421142578125,1.5732738971710205,8.077890396118164,-11.773564338684082,-19.127399444580078,-23.15826416015625,-0.41270700097084045,0.09131022542715073,-10.452750205993652,-17.814855575561523,20.55525016784668,-21.274757385253906,-8.646486282348633,-4.147698402404785,-21.279560089111328,-21.386795043945312,18.595129013061523,-21.340486526489258,23.919536590576172,8.554425239562988,-13.873297691345215,13.545158386230469,1.4652202129364014,4.61568546295166,2.0211174488067627,8.55898380279541,-5.096734523773193,13.47661018371582,-19.74725914001465,10.069114685058594,-10.41120433807373,-21.325580596923828,-5.611347675323486,7.7699995040893555,12.67944049835205,-9.264848709106445,17.343650817871094,-1.9219313859939575,-6.726968288421631,11.755054473876953,-0.1998438686132431,18.65003776550293,-26.500303268432617,-30.1773681640625,-18.160356521606445,5.821072578430176,4.459037780761719,-0.9969910979270935,6.191136360168457,25.586376190185547,-0.6688490509986877,0.14656122028827667,34.70937728881836,20.15680503845215,0.3528505265712738,-27.59568977355957,-14.051470756530762,0.5039492249488831,-30.592439651489258,-20.59027099609375,-14.01789665222168,16.898365020751953,9.024813652038574,-20.58918571472168,-25.739423751831055,-3.5005455017089844,-20.81452751159668,26.441225051879883,5.795555591583252,-26.197288513183594,2.82038950920105,26.46295928955078,-8.07242202758789,25.41840934753418,0.4250914454460144,5.404520034790039,14.45012378692627,-15.178555488586426,5.7341084480285645,-9.213237762451172,9.834942817687988,-0.7060266137123108,21.658931732177734,0.6760771870613098,-1.3957550525665283,20.89692497253418,-2.2352025508880615,31.582338333129883],\"y\":[-19.565061569213867,12.972709655761719,32.708778381347656,10.156662940979004,15.85457706451416,-18.176542282104492,19.432891845703125,1.9967944622039795,22.88096046447754,14.291733741760254,-6.580297946929932,8.174015998840332,-23.321239471435547,-13.536648750305176,21.655353546142578,-30.09641456604004,-26.476959228515625,-30.687725067138672,-26.636093139648438,-18.53120994567871,-8.90441608428955,15.326948165893555,17.39997673034668,2.5214571952819824,28.390544891357422,27.169715881347656,13.9437837600708,11.186094284057617,-13.344324111938477,14.546948432922363,-23.69789695739746,-7.284426689147949,-18.583126068115234,-0.7623217105865479,-24.2570858001709,29.907384872436523,7.418662071228027,26.806394577026367,-20.636959075927734,-9.255660057067871,2.4363999366760254,-9.399764060974121,6.917270660400391,13.062477111816406,35.77167892456055,14.849725723266602,0.22173860669136047,-5.495014667510986,32.708778381347656,20.097274780273438,12.739068984985352,-0.08747287094593048,-23.20477867126465,-35.92174530029297,12.384406089782715,22.20282745361328,-22.2463321685791,-2.6035637855529785,22.876575469970703,-7.3698344230651855,6.580381393432617,-28.787105560302734,14.45254898071289,10.276640892028809,-2.5479962825775146,23.29096794128418,-6.297336101531982,-3.8926656246185303,3.225135326385498,1.6920416355133057,-20.143932342529297,-6.936279296875,-4.363474369049072,15.051740646362305,-25.247339248657227,-0.9594714641571045,-3.299360752105713,-23.8116455078125,-17.37805938720703,17.65997886657715,-13.702000617980957,22.336530685424805,9.396916389465332,6.11634635925293,-24.190305709838867,-33.604469299316406,9.07376766204834,10.967486381530762,26.742122650146484,0.06332381814718246,4.898105144500732,-0.5782285928726196,-10.385408401489258,-13.338469505310059,-18.098102569580078,-12.122685432434082,8.629150390625,-26.449674606323242,-8.434972763061523,-10.437775611877441,32.239952087402344,23.523435592651367,-23.420377731323242,-14.096311569213867,-8.67379093170166,-21.903488159179688,10.990738868713379,9.19929027557373,18.480392456054688,-18.375167846679688,6.377752780914307,-0.22678916156291962,-17.952007293701172,29.200660705566406,-2.7312655448913574,2.8302087783813477,32.84067916870117,-26.795278549194336,-15.317228317260742,22.49578285217285,6.7893829345703125,-6.994426727294922,9.766036033630371,-13.914311408996582,-1.483919620513916,21.84842872619629,-2.7385847568511963,-0.7246487140655518,-17.434444427490234,-17.176912307739258,27.12818717956543,6.912076950073242,25.96769142150879,29.33637046813965,8.6218843460083,-14.972007751464844,23.892229080200195,9.786320686340332,0.030690548941493034,-15.273947715759277,-11.047738075256348,-8.463370323181152,-14.747989654541016,13.578055381774902,-14.21500015258789,-18.007986068725586,-16.85710906982422,-10.360394477844238,-32.916202545166016,-28.84761619567871,24.973508834838867,14.061267852783203,-10.099957466125488,3.7156240940093994,-14.01179027557373,1.035504698753357,22.45069122314453,0.7894625067710876,-17.97422218322754,-3.9168572425842285,6.070677757263184,-33.88887023925781,18.617952346801758,1.6390875577926636,13.979439735412598,-30.444061279296875,8.27627944946289,-4.343962669372559,-1.6421160697937012,3.9966208934783936,-15.65979290008545,13.161166191101074,7.404988765716553,-0.01568727195262909,-22.013154983520508,24.3455810546875,16.012067794799805,-0.715519905090332,-10.995437622070312,-20.561965942382812,-33.626827239990234,16.094520568847656,-14.134016990661621,22.29488182067871,9.042275428771973,-1.2926808595657349,13.707171440124512,23.05219841003418,20.042753219604492,7.935708045959473,7.8090434074401855,7.2091169357299805,7.120147228240967,20.383556365966797,2.3035380840301514,8.291208267211914,6.2852582931518555,13.160207748413086,-18.28925132751465,3.932295560836792,-1.5045039653778076,6.579398155212402,23.211841583251953,-22.52239227294922,10.230804443359375,-18.921823501586914,-0.9958261847496033,-18.723817825317383,-26.584232330322266,6.563270568847656,-6.022783279418945,-6.496072292327881,-10.605510711669922,-1.8969939947128296,4.381251335144043,-27.128347396850586,-6.225554466247559,4.46674108505249,-1.8316742181777954,-29.388214111328125,-2.1219639778137207,-8.804773330688477,-15.145816802978516,5.090423583984375,-17.299272537231445,7.403828144073486,5.645294189453125,-24.838363647460938,29.26618003845215,3.257415294647217,-13.622774124145508,25.913543701171875,10.464361190795898,-7.1440935134887695,14.62292194366455,-5.026586532592773,17.90184783935547,31.42319107055664,2.923182249069214,1.302377700805664,4.61155366897583,16.217548370361328,14.402228355407715,18.13615608215332,9.11400032043457,-35.083351135253906,-7.092837810516357,19.406511306762695,-28.783761978149414,19.769636154174805,11.771708488464355,10.691073417663574,-18.87657928466797,11.112630844116211,7.522909641265869,2.6323230266571045,25.296247482299805,3.0132861137390137,-17.513370513916016,-23.32064437866211,13.289856910705566,-8.370158195495605,-12.412936210632324,-0.8750098347663879,18.60875129699707,8.34118938446045,17.8314266204834,-7.53953218460083,-26.02435874938965,9.544107437133789,-20.908517837524414,-1.8506243228912354,-23.3638858795166,18.75568962097168,-22.81842613220215,23.386165618896484,5.037643909454346,-4.11886739730835,-4.125361919403076,6.763443470001221,-5.035355091094971,27.63375473022461,-19.48543357849121,-0.9115461707115173,-26.273691177368164,11.214624404907227,12.329343795776367,4.544979095458984,-3.065309762954712,-12.246082305908203,-18.209827423095703,-1.8262704610824585,-23.549976348876953,-20.501117706298828,15.501730918884277,-10.367463111877441,-4.41793966293335,0.629551351070404,0.31188759207725525,0.574367105960846,6.267780303955078,13.166582107543945,-0.7483004331588745,-21.062265396118164,12.976973533630371,7.224847793579102,16.974061965942383,-26.997467041015625,14.639050483703613,-11.651752471923828,12.667245864868164,-1.9974015951156616,-35.87270736694336,5.122635364532471,1.4688022136688232,-7.8318562507629395,-1.9643502235412598,0.8887205719947815,-19.546634674072266,-19.780536651611328,8.494900703430176,-34.263851165771484,30.282329559326172,6.744216442108154,17.405282974243164,-26.505538940429688,-7.399200916290283,7.671241760253906,-29.824331283569336,14.825623512268066,-21.323833465576172,25.996627807617188,2.8919100761413574,7.2368597984313965,11.123920440673828,-1.919157862663269,15.420138359069824,-18.981401443481445,-24.486421585083008,16.13810157775879,15.265603065490723,28.558528900146484,2.169113874435425,-5.752763271331787,-22.43382453918457,21.883317947387695,30.12533187866211,-8.274534225463867,0.7824195027351379,-5.6709394454956055,27.404672622680664,-0.21797341108322144,9.328737258911133,19.428096771240234,0.18391814827919006,5.157559394836426,1.8994375467300415,18.02570915222168,2.1442160606384277,-36.550960540771484,-15.478178024291992,-31.565011978149414,29.53009033203125,-12.795538902282715,27.839082717895508,-9.241092681884766,30.476402282714844,-32.11978530883789,-8.309847831726074,-5.997226715087891,8.476126670837402,16.143115997314453,-9.341296195983887,-25.231704711914062,15.585503578186035,17.892826080322266,-12.653239250183105,-8.881996154785156,6.442929744720459,16.265430450439453,-33.24225616455078,-26.98597526550293,-11.007686614990234,-15.171879768371582,5.469862937927246,-6.074959754943848,-9.280653953552246,-7.838982582092285,-18.045907974243164,-2.8083388805389404,12.695199966430664,-28.808443069458008,-2.86421537399292,-15.055739402770996,9.281270027160645,-12.635427474975586,-13.459329605102539,-3.1678576469421387,19.368242263793945,-2.64509654045105,13.936274528503418,5.86928129196167,2.2646071910858154,21.216346740722656,0.7777862548828125,29.634166717529297,4.321739673614502,5.203261852264404,-30.030672073364258,-19.665897369384766,-33.62889099121094,-17.098417282104492,-19.713584899902344,-31.044137954711914,16.78200912475586,-2.1425986289978027,-9.449158668518066,0.7296812534332275,8.859200477600098,13.493829727172852,14.515528678894043,-12.953513145446777,17.159137725830078,-0.7016915082931519,-12.845086097717285,-32.38084411621094,-17.72687339782715,-26.595842361450195,27.758880615234375,-11.921557426452637,22.869367599487305,20.616119384765625,12.974939346313477,26.916866302490234,4.2675299644470215,-16.81696319580078,-30.778793334960938,1.2501089572906494,22.217653274536133,-4.981279373168945,-12.517245292663574,-9.063629150390625,12.0816011428833,-24.89948081970215,24.500083923339844,-14.586005210876465,-7.623777389526367,18.369823455810547,16.042234420776367,-32.33731460571289,16.39380645751953,1.1335103511810303,29.687576293945312,13.889212608337402,2.183926820755005,-0.7301977276802063,-15.001350402832031,17.879962921142578,-4.643556118011475,3.4217255115509033,-19.676300048828125,-6.97520112991333,5.506978511810303,-20.761932373046875,9.98117733001709,26.05562400817871,-12.321488380432129,-8.343052864074707,-18.39393424987793,-7.5554046630859375,-0.6738782525062561,-23.460752487182617,-10.942164421081543,11.8069429397583,-7.652421474456787,-2.3714840412139893,12.905916213989258,-28.682024002075195,-33.878692626953125,-11.472284317016602,-22.861427307128906,-26.281171798706055,20.5043888092041,-6.909748077392578,18.97536849975586,23.27009391784668,5.697068691253662,5.592663288116455,17.828794479370117,-28.85395622253418,-13.500382423400879,-27.007381439208984,-22.095308303833008,-3.09671688079834,7.777196407318115,-9.73245620727539,9.822657585144043,-21.177440643310547,-13.516125679016113,12.853507995605469],\"z\":[10.73459529876709,-10.96172046661377,3.7508158683776855,14.635650634765625,-4.857732772827148,-15.526703834533691,10.691201210021973,14.643636703491211,8.072508811950684,-9.490948677062988,-10.012429237365723,1.7313146591186523,-0.6895368695259094,0.6686510443687439,4.902085304260254,-5.57536506652832,-12.026297569274902,1.3808479309082031,19.837736129760742,-14.445221900939941,-6.388391017913818,16.960487365722656,1.3510349988937378,-11.078697204589844,14.709620475769043,3.0174190998077393,5.48807430267334,9.442255020141602,-2.097651720046997,9.617788314819336,-3.0972092151641846,-9.904913902282715,1.742210865020752,-7.154552459716797,18.88640785217285,8.406909942626953,-0.2703835964202881,2.6411473751068115,-8.41676139831543,0.7250900864601135,-16.466455459594727,20.282522201538086,17.677091598510742,4.670831680297852,3.4115958213806152,19.42253303527832,2.13976788520813,7.342026233673096,10.324333190917969,11.587669372558594,-3.1636791229248047,-1.7500402927398682,12.993109703063965,-5.169879913330078,-7.304599285125732,14.16360092163086,-13.425843238830566,-9.598570823669434,13.362305641174316,12.407827377319336,9.737953186035156,10.59965991973877,-0.042786918580532074,-2.3944454193115234,-2.617250680923462,-15.279559135437012,-14.841524124145508,-5.719468593597412,2.099261522293091,8.157285690307617,-10.486185073852539,7.796473026275635,-9.14352798461914,24.729352951049805,0.43094757199287415,-6.621151924133301,-18.189729690551758,-9.545696258544922,-14.143694877624512,10.742515563964844,-10.796361923217773,-3.3003785610198975,1.1063456535339355,12.262510299682617,-17.594850540161133,5.827391624450684,8.49255657196045,-3.4713449478149414,-1.5443594455718994,7.956095218658447,2.7919108867645264,12.35093879699707,-7.496994972229004,-8.4614896774292,1.8617173433303833,-21.197498321533203,2.7341103553771973,-6.893189430236816,-6.436577320098877,-12.481728553771973,-11.72636890411377,-10.266308784484863,-2.555140733718872,5.470560550689697,-17.413875579833984,-21.975645065307617,-6.115028381347656,-8.84449291229248,-6.853452682495117,6.256643772125244,18.6527156829834,9.021696090698242,-3.578021287918091,-13.017979621887207,-6.644229412078857,-7.258438587188721,-0.9287289381027222,2.0763449668884277,-6.592375755310059,8.608573913574219,1.0307940244674683,-16.479455947875977,4.412287712097168,21.20382308959961,20.663911819458008,-19.307100296020508,4.973994255065918,-2.735013008117676,-8.621034622192383,1.5686964988708496,2.2121834754943848,20.609304428100586,1.2860535383224487,7.682787895202637,-14.134602546691895,-0.8176398277282715,4.978049278259277,3.707667112350464,27.027746200561523,-1.593960165977478,-27.69594955444336,-6.910224437713623,3.007596492767334,7.605903625488281,-9.681757926940918,-2.593337059020996,-9.284164428710938,-0.5341878533363342,-2.069181203842163,-9.057964324951172,-11.35983657836914,-0.21003864705562592,-3.225179672241211,6.646986484527588,-6.0724029541015625,25.000614166259766,2.3223562240600586,8.713102340698242,-5.743058204650879,-1.8250877857208252,-19.126018524169922,13.5025053024292,7.429455757141113,16.752487182617188,-8.917061805725098,-11.43057918548584,-15.495038986206055,17.287353515625,3.285688638687134,5.820281028747559,12.56326961517334,14.237439155578613,18.893997192382812,7.329082489013672,3.819220781326294,8.702861785888672,11.349233627319336,-18.12108612060547,-9.32828426361084,14.82059383392334,-8.660456657409668,-6.948146820068359,1.713455319404602,2.925828695297241,10.6297607421875,-5.1418776512146,8.341377258300781,-3.505156993865967,-11.421441078186035,-10.15837574005127,-2.4172983169555664,-11.89959716796875,14.266145706176758,-6.10960054397583,0.2461642026901245,22.49262237548828,0.9479357004165649,-1.687798023223877,7.3280534744262695,6.750186920166016,-3.7108285427093506,-5.6788835525512695,-2.4802422523498535,8.17367935180664,3.84810733795166,1.835243582725525,-7.794912338256836,17.697832107543945,-3.169639825820923,-0.9165427684783936,25.272552490234375,-8.301495552062988,14.37834358215332,24.645118713378906,7.935464859008789,-6.263963222503662,14.116676330566406,9.547669410705566,-25.502599716186523,-10.125060081481934,-2.4313457012176514,14.249503135681152,-11.778681755065918,-25.132164001464844,-6.001509666442871,8.453453063964844,-0.032979194074869156,17.587528228759766,-6.553031921386719,3.3794379234313965,18.27322769165039,-3.644294261932373,0.9716961979866028,-8.639227867126465,-10.765520095825195,-13.708043098449707,-1.0278360843658447,-13.034259796142578,27.19215965270996,-13.331099510192871,-14.930672645568848,15.77807903289795,7.4736104011535645,-10.405211448669434,-21.08637237548828,1.864580512046814,13.638310432434082,14.471216201782227,-14.856219291687012,6.981356143951416,-15.753107070922852,-11.765220642089844,-11.059755325317383,-12.496367454528809,-6.00291109085083,-7.061835289001465,7.158290863037109,-0.19248370826244354,16.8312931060791,-9.96703815460205,21.38373374938965,-3.715686798095703,-12.284293174743652,18.024517059326172,-14.89745044708252,-3.9999802112579346,4.344533443450928,-1.8821943998336792,-9.66278076171875,4.649289131164551,-0.6357242465019226,2.889566659927368,-17.724605560302734,-8.81588363647461,-5.550693988800049,4.2810492515563965,7.280314922332764,-7.321569919586182,-23.379344940185547,-8.936692237854004,12.136451721191406,13.702895164489746,-1.8252403736114502,2.647052764892578,11.688817977905273,13.899913787841797,-2.914909601211548,-9.42304801940918,-2.574551582336426,21.872209548950195,9.022120475769043,-17.486936569213867,-0.07255665212869644,5.345261096954346,-14.262356758117676,4.266498565673828,-12.489840507507324,-15.343503952026367,-14.307920455932617,-0.2941533327102661,-21.7800350189209,1.822325587272644,5.58722448348999,21.09986114501953,-7.7596435546875,-17.978551864624023,12.183914184570312,2.937760829925537,-2.240109443664551,-4.938324451446533,3.6924800872802734,-9.686639785766602,-12.138386726379395,0.1713719367980957,2.7876040935516357,12.554484367370605,-16.757017135620117,9.41653823852539,16.195289611816406,0.2668360471725464,-10.360519409179688,-4.950760364532471,12.27345085144043,-0.8109502792358398,2.7630372047424316,-0.5371642112731934,5.641699314117432,-8.536412239074707,16.108415603637695,2.666839838027954,-17.88357162475586,12.764966011047363,13.588685035705566,-5.0987162590026855,-13.040247917175293,10.473994255065918,-9.81448745727539,4.03355598449707,14.939305305480957,17.62727165222168,-7.761981964111328,16.643444061279297,-17.89449691772461,-12.022801399230957,-20.962697982788086,4.184440612792969,-1.724435567855835,6.492467403411865,-23.323406219482422,4.237431526184082,9.542835235595703,19.371463775634766,7.5418195724487305,4.557328224182129,-0.6706544756889343,-15.337223052978516,-12.746915817260742,0.048128098249435425,-12.12382698059082,-1.3800712823867798,15.825690269470215,-5.9949631690979,2.762805700302124,-11.847373008728027,-5.803930759429932,-4.950921535491943,6.894760608673096,-10.613637924194336,-11.58799934387207,17.050533294677734,4.96690559387207,19.906171798706055,3.023291826248169,-5.957276344299316,15.441365242004395,13.66794490814209,3.0559096336364746,-20.265995025634766,-6.029062747955322,-2.354369878768921,-9.145686149597168,18.617589950561523,-2.871654987335205,6.426254749298096,12.539960861206055,-26.64133071899414,-23.469179153442383,4.139773368835449,11.209123611450195,16.903135299682617,-6.0138936042785645,-14.460403442382812,-11.825874328613281,6.959732532501221,12.145221710205078,16.17425537109375,6.226290225982666,3.4712259769439697,-6.392050266265869,13.241929054260254,-5.749809265136719,3.0051913261413574,-6.019277095794678,-11.08981990814209,-25.37260627746582,11.74850845336914,-3.786639928817749,2.1739847660064697,11.676117897033691,-7.443451881408691,-13.9722261428833,2.2498598098754883,-3.5298104286193848,-2.7329788208007812,0.3404526710510254,3.0104005336761475,3.0734596252441406,-11.96651840209961,-10.266030311584473,-18.234542846679688,-14.194456100463867,12.08963680267334,-1.436566948890686,10.137924194335938,10.589404106140137,-1.1601823568344116,-17.064186096191406,-7.4369988441467285,8.286283493041992,-4.457813262939453,-4.322021961212158,2.9218850135803223,12.78711223602295,1.2969636917114258,-6.5859456062316895,-25.05000114440918,10.298295021057129,2.7900874614715576,12.14923095703125,4.539860725402832,-19.433225631713867,6.5170464515686035,0.6494920253753662,-1.5791908502578735,-8.387679100036621,-10.510244369506836,-3.0237250328063965,3.097668409347534,-8.305900573730469,16.437776565551758,17.92662239074707,17.49840545654297,3.2580347061157227,19.06608772277832,20.615398406982422,14.207584381103516,-4.619909286499023,10.13376235961914,-6.607334613800049,-19.496566772460938,-22.011234283447266,6.912737846374512,-2.0342230796813965,10.632221221923828,3.9591853618621826,-2.0232222080230713,-24.28082275390625,-1.5734586715698242,-16.383255004882812,-1.3231631517410278,-1.4180505275726318,-21.750871658325195,1.4907643795013428,8.774182319641113,-2.3903892040252686,20.25430679321289,17.677675247192383,18.292465209960938,-8.48665714263916,3.725896120071411,20.119813919067383,5.4032301902771,-0.34818482398986816,1.1251825094223022,-1.1851400136947632,-8.55270767211914,5.367623805999756,14.853727340698242,-2.5886807441711426,-13.36812686920166,-3.865652561187744,-14.105588912963867,-21.102619171142578,-12.889476776123047,4.701853275299072,-13.984855651855469,-1.9256374835968018,4.113271713256836,-6.99816370010376,7.009118556976318],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0e3c44f3-523c-4a79-ad86-c27cb4b29f49');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter_3d(x=x, y=y, z=z)\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4AIuIruYHlL"
      },
      "source": [
        "Well that's a not a particularly interesting 3d plot! \n",
        "- How about we label some of the points on the graph to see what words they correspond to:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "nwF1aJAQy9YY",
        "outputId": "192b7187-dd5f-49e9-9fd4-63f882fd76e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"2fcb1354-a36d-416c-ad90-59cd101ce667\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2fcb1354-a36d-416c-ad90-59cd101ce667\")) {                    Plotly.newPlot(                        \"2fcb1354-a36d-416c-ad90-59cd101ce667\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>z=%{z}<br>text=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"line\":{\"width\":2},\"size\":3},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"filters\",\"cream\",\"ceremonies\",\"hesketh\",\"mandated\",\"1950\",\"insists\",\"wingate\",\"staunch\",\"graduated\",\"caratzas\",\"ajwmw\",\"former\",\"0l\",\"wailing\",\"602\",\"toyota\",\"politics\",\"frame\",\"30pm\",\"tray\",\"reminded\",\"rouge\",\"1959\",\"treaties\",\"salah\",\"cathy\",\"paganism\",\"msfc\",\"ariv\",\"labs\",\"mcintyre\",\"gr\",\"5a\",\"des\",\"offender\",\"aum\",\"abide\",\"columbus\",\"geostationary\",\"babylon\",\"directly\",\"leaves\",\"strengths\",\"confined\",\"roderick\",\"flawed\",\"abusive\",\"insofar\",\"npr\",\"986\",\"remarkably\",\"tables\",\"thu\",\"ntr\",\"overwhelmed\",\"expos\",\"hci\",\"gca\",\"hints\",\"credibility\",\"upgrade\",\"herpesvirus\",\"mahaffey\",\"se1\",\"smoothing\",\"wha\",\"x74\",\"ngt\",\"lord\",\"284\",\"gift\",\"radically\",\"aclu\",\"regards\",\"654\",\"revenge\",\"hamilton\",\"248\",\"pregnant\",\"turk\",\"sixties\",\"501\",\"passport\",\"ohm\",\"pub\",\"l8\",\"legend\",\"breakdown\",\"misunderstand\",\"politicians\",\"foia\",\"882\",\"slaughter\",\"occupation\",\"tail\",\"shocking\",\"305\",\"6ej\",\"grad\",\"havn\",\"spanking\",\"coli\",\"explosive\",\"occurred\",\"comparable\",\"denoted\",\"pclk\",\"hiking\",\"removal\",\"excuse\",\"responds\",\"mcnulty\",\"tricks\",\"pposition\",\"academics\",\"powerless\",\"association\",\"75di\",\"deficiencies\",\"br_\",\"boarding\",\"i2j\",\"direct\",\"depend\",\"bounce\",\"infra\",\"southy\",\"owned\",\"rockefeller\",\"thriving\",\"another\",\"godly\",\"nagarno\",\"dwi\",\"circumference\",\"irenaeus\",\"stationary\",\"follow\",\"burrows\",\"removed\",\"j75u\",\"collision\",\"ingredients\",\"314\",\"hunting\",\"sheffield\",\"d2_\",\"january\",\"houston\",\"alley\",\"1033\",\"lt\",\"nkhf\",\"utrecht\",\"book\",\"hite\",\"supervisor\",\"equ\",\"engaging\",\"isaiah\",\"card\",\"mds\",\"rip\",\"bcopy\",\"275\",\"jdr\",\"approach\",\"qs4u\",\"wl\",\"kernel\",\"15am\",\"blindness\",\"supernatural\",\"win3\",\"pathway\",\"sinking\",\"seventh\",\"rz350\",\"supported\",\"805\",\"cornering\",\"zq\",\"6w8\",\"comma\",\"ops\",\"pity\",\"woofers\",\"nowadays\",\"powering\",\"outdated\",\"oxide\",\"conforms\",\"malaria\",\"racism\",\"gopher\",\"membrane\",\"umanitoba\",\"4l\",\"gender\"],\"x\":[-5.288376331329346,-7.399438381195068,3.143462896347046,11.211236000061035,-11.905241966247559,-8.192967414855957,-8.915616035461426,8.269021034240723,0.6238380670547485,9.979178428649902,7.9605393409729,31.394201278686523,-26.799314498901367,28.418731689453125,-16.08221435546875,-7.450580596923828,10.409594535827637,6.0566182136535645,-1.0221208333969116,1.2604206800460815,-4.637762069702148,-11.505729675292969,12.484148979187012,-18.665451049804688,-0.179735466837883,18.5765438079834,25.356639862060547,-0.18982532620429993,0.7756959199905396,26.01319122314453,-3.9958229064941406,2.471705436706543,10.991164207458496,21.9027156829834,-11.016947746276855,8.300216674804688,38.19407653808594,27.67820167541504,-5.458894729614258,4.114339828491211,-24.614362716674805,-5.978143215179443,-10.487565040588379,5.039451599121094,15.333364486694336,-3.434523344039917,-20.253602981567383,-8.898650169372559,0.8429838418960571,26.020719528198242,12.736211776733398,-17.820377349853516,-4.063958168029785,-4.3155364990234375,18.774024963378906,9.633091926574707,-12.068949699401855,-27.050472259521484,1.9245821237564087,-6.160740375518799,-14.213034629821777,7.130969047546387,34.61437225341797,-5.956613063812256,25.820022583007812,-11.72714900970459,13.473323822021484,20.63051414489746,29.069660186767578,-34.14004898071289,-1.9197895526885986,-23.85382652282715,-12.440592765808105,7.404250621795654,-8.90417766571045,9.655231475830078,0.6680594682693481,-13.269638061523438,6.569542407989502,-21.875425338745117,-12.697641372680664,-0.791601836681366,3.271703004837036,14.40322494506836,2.832347869873047,-6.99981164932251,23.065526962280273,-21.08306884765625,-9.549190521240234,-9.092395782470703,-27.177366256713867,3.9847071170806885,7.253046035766602,-29.115633010864258,-27.12983512878418,-4.359943866729736,-1.013936996459961,-7.555912971496582,21.59099006652832,-5.599700450897217,18.099367141723633,9.278861045837402,-12.038290977478027,-17.90552520751953,-25.50333595275879,-5.415999889373779,22.785982131958008,5.636483192443848,4.119478702545166,-9.280073165893555,-14.8136625289917,-2.5445053577423096,-3.3166253566741943,-0.2401885986328125,-1.649182677268982,-23.648231506347656,9.522090911865234,-24.621599197387695,16.231380462646484,6.815588474273682,19.597511291503906,6.3170247077941895,28.643156051635742,-5.1254496574401855,-11.922690391540527,3.8780651092529297,3.476881742477417,11.651019096374512,-18.715343475341797,-23.903669357299805,8.417810440063477,-26.31454849243164,1.485678791999817,-9.134273529052734,-2.8143556118011475,12.524828910827637,4.914846897125244,9.38978099822998,-3.9955475330352783,-5.702243328094482,-6.531413555145264,16.54492950439453,0.6139834523200989,-8.034163475036621,3.6246836185455322,-11.22579574584961,-7.796806335449219,17.474166870117188,-17.176538467407227,-15.235148429870605,17.247575759887695,22.49347686767578,25.985902786254883,24.669757843017578,11.068037033081055,-27.94687843322754,16.169876098632812,14.612735748291016,1.326439619064331,-13.584102630615234,-24.817378997802734,5.314001083374023,19.32957649230957,-6.654120922088623,30.142671585083008,-6.185067653656006,20.584856033325195,-23.41428565979004,29.15624237060547,32.63324737548828,-4.20383358001709,22.176664352416992,2.140807867050171,-24.075105667114258,3.7895424365997314,14.157355308532715,11.352256774902344,-22.46864891052246,-1.683305263519287,-15.001409530639648,-9.296624183654785,-1.2682331800460815,23.616483688354492,11.980846405029297,5.9747796058654785,-16.42572784423828,-20.453771591186523,18.083131790161133,-0.11302213370800018,18.42504119873047,4.66042947769165,-15.18731689453125,-1.073417067527771,-13.670775413513184,-30.146665573120117,13.995789527893066,-12.728890419006348,3.9593441486358643,21.071895599365234,-20.88743782043457],\"y\":[-19.565061569213867,12.972709655761719,32.708778381347656,10.156662940979004,15.85457706451416,-18.176542282104492,19.432891845703125,1.9967944622039795,22.88096046447754,14.291733741760254,-6.580297946929932,8.174015998840332,-23.321239471435547,-13.536648750305176,21.655353546142578,-30.09641456604004,-26.476959228515625,-30.687725067138672,-26.636093139648438,-18.53120994567871,-8.90441608428955,15.326948165893555,17.39997673034668,2.5214571952819824,28.390544891357422,27.169715881347656,13.9437837600708,11.186094284057617,-13.344324111938477,14.546948432922363,-23.69789695739746,-7.284426689147949,-18.583126068115234,-0.7623217105865479,-24.2570858001709,29.907384872436523,7.418662071228027,26.806394577026367,-20.636959075927734,-9.255660057067871,2.4363999366760254,-9.399764060974121,6.917270660400391,13.062477111816406,35.77167892456055,14.849725723266602,0.22173860669136047,-5.495014667510986,32.708778381347656,20.097274780273438,12.739068984985352,-0.08747287094593048,-23.20477867126465,-35.92174530029297,12.384406089782715,22.20282745361328,-22.2463321685791,-2.6035637855529785,22.876575469970703,-7.3698344230651855,6.580381393432617,-28.787105560302734,14.45254898071289,10.276640892028809,-2.5479962825775146,23.29096794128418,-6.297336101531982,-3.8926656246185303,3.225135326385498,1.6920416355133057,-20.143932342529297,-6.936279296875,-4.363474369049072,15.051740646362305,-25.247339248657227,-0.9594714641571045,-3.299360752105713,-23.8116455078125,-17.37805938720703,17.65997886657715,-13.702000617980957,22.336530685424805,9.396916389465332,6.11634635925293,-24.190305709838867,-33.604469299316406,9.07376766204834,10.967486381530762,26.742122650146484,0.06332381814718246,4.898105144500732,-0.5782285928726196,-10.385408401489258,-13.338469505310059,-18.098102569580078,-12.122685432434082,8.629150390625,-26.449674606323242,-8.434972763061523,-10.437775611877441,32.239952087402344,23.523435592651367,-23.420377731323242,-14.096311569213867,-8.67379093170166,-21.903488159179688,10.990738868713379,9.19929027557373,18.480392456054688,-18.375167846679688,6.377752780914307,-0.22678916156291962,-17.952007293701172,29.200660705566406,-2.7312655448913574,2.8302087783813477,32.84067916870117,-26.795278549194336,-15.317228317260742,22.49578285217285,6.7893829345703125,-6.994426727294922,9.766036033630371,-13.914311408996582,-1.483919620513916,21.84842872619629,-2.7385847568511963,-0.7246487140655518,-17.434444427490234,-17.176912307739258,27.12818717956543,6.912076950073242,25.96769142150879,29.33637046813965,8.6218843460083,-14.972007751464844,23.892229080200195,9.786320686340332,0.030690548941493034,-15.273947715759277,-11.047738075256348,-8.463370323181152,-14.747989654541016,13.578055381774902,-14.21500015258789,-18.007986068725586,-16.85710906982422,-10.360394477844238,-32.916202545166016,-28.84761619567871,24.973508834838867,14.061267852783203,-10.099957466125488,3.7156240940093994,-14.01179027557373,1.035504698753357,22.45069122314453,0.7894625067710876,-17.97422218322754,-3.9168572425842285,6.070677757263184,-33.88887023925781,18.617952346801758,1.6390875577926636,13.979439735412598,-30.444061279296875,8.27627944946289,-4.343962669372559,-1.6421160697937012,3.9966208934783936,-15.65979290008545,13.161166191101074,7.404988765716553,-0.01568727195262909,-22.013154983520508,24.3455810546875,16.012067794799805,-0.715519905090332,-10.995437622070312,-20.561965942382812,-33.626827239990234,16.094520568847656,-14.134016990661621,22.29488182067871,9.042275428771973,-1.2926808595657349,13.707171440124512,23.05219841003418,20.042753219604492,7.935708045959473,7.8090434074401855,7.2091169357299805,7.120147228240967,20.383556365966797,2.3035380840301514,8.291208267211914,6.2852582931518555,13.160207748413086,-18.28925132751465,3.932295560836792],\"z\":[10.73459529876709,-10.96172046661377,3.7508158683776855,14.635650634765625,-4.857732772827148,-15.526703834533691,10.691201210021973,14.643636703491211,8.072508811950684,-9.490948677062988,-10.012429237365723,1.7313146591186523,-0.6895368695259094,0.6686510443687439,4.902085304260254,-5.57536506652832,-12.026297569274902,1.3808479309082031,19.837736129760742,-14.445221900939941,-6.388391017913818,16.960487365722656,1.3510349988937378,-11.078697204589844,14.709620475769043,3.0174190998077393,5.48807430267334,9.442255020141602,-2.097651720046997,9.617788314819336,-3.0972092151641846,-9.904913902282715,1.742210865020752,-7.154552459716797,18.88640785217285,8.406909942626953,-0.2703835964202881,2.6411473751068115,-8.41676139831543,0.7250900864601135,-16.466455459594727,20.282522201538086,17.677091598510742,4.670831680297852,3.4115958213806152,19.42253303527832,2.13976788520813,7.342026233673096,10.324333190917969,11.587669372558594,-3.1636791229248047,-1.7500402927398682,12.993109703063965,-5.169879913330078,-7.304599285125732,14.16360092163086,-13.425843238830566,-9.598570823669434,13.362305641174316,12.407827377319336,9.737953186035156,10.59965991973877,-0.042786918580532074,-2.3944454193115234,-2.617250680923462,-15.279559135437012,-14.841524124145508,-5.719468593597412,2.099261522293091,8.157285690307617,-10.486185073852539,7.796473026275635,-9.14352798461914,24.729352951049805,0.43094757199287415,-6.621151924133301,-18.189729690551758,-9.545696258544922,-14.143694877624512,10.742515563964844,-10.796361923217773,-3.3003785610198975,1.1063456535339355,12.262510299682617,-17.594850540161133,5.827391624450684,8.49255657196045,-3.4713449478149414,-1.5443594455718994,7.956095218658447,2.7919108867645264,12.35093879699707,-7.496994972229004,-8.4614896774292,1.8617173433303833,-21.197498321533203,2.7341103553771973,-6.893189430236816,-6.436577320098877,-12.481728553771973,-11.72636890411377,-10.266308784484863,-2.555140733718872,5.470560550689697,-17.413875579833984,-21.975645065307617,-6.115028381347656,-8.84449291229248,-6.853452682495117,6.256643772125244,18.6527156829834,9.021696090698242,-3.578021287918091,-13.017979621887207,-6.644229412078857,-7.258438587188721,-0.9287289381027222,2.0763449668884277,-6.592375755310059,8.608573913574219,1.0307940244674683,-16.479455947875977,4.412287712097168,21.20382308959961,20.663911819458008,-19.307100296020508,4.973994255065918,-2.735013008117676,-8.621034622192383,1.5686964988708496,2.2121834754943848,20.609304428100586,1.2860535383224487,7.682787895202637,-14.134602546691895,-0.8176398277282715,4.978049278259277,3.707667112350464,27.027746200561523,-1.593960165977478,-27.69594955444336,-6.910224437713623,3.007596492767334,7.605903625488281,-9.681757926940918,-2.593337059020996,-9.284164428710938,-0.5341878533363342,-2.069181203842163,-9.057964324951172,-11.35983657836914,-0.21003864705562592,-3.225179672241211,6.646986484527588,-6.0724029541015625,25.000614166259766,2.3223562240600586,8.713102340698242,-5.743058204650879,-1.8250877857208252,-19.126018524169922,13.5025053024292,7.429455757141113,16.752487182617188,-8.917061805725098,-11.43057918548584,-15.495038986206055,17.287353515625,3.285688638687134,5.820281028747559,12.56326961517334,14.237439155578613,18.893997192382812,7.329082489013672,3.819220781326294,8.702861785888672,11.349233627319336,-18.12108612060547,-9.32828426361084,14.82059383392334,-8.660456657409668,-6.948146820068359,1.713455319404602,2.925828695297241,10.6297607421875,-5.1418776512146,8.341377258300781,-3.505156993865967,-11.421441078186035,-10.15837574005127,-2.4172983169555664,-11.89959716796875,14.266145706176758,-6.10960054397583,0.2461642026901245,22.49262237548828,0.9479357004165649,-1.687798023223877,7.3280534744262695,6.750186920166016],\"type\":\"scatter3d\",\"textfont\":{\"size\":10}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('2fcb1354-a36d-416c-ad90-59cd101ce667');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = px.scatter_3d(x=x[:200],y=y[:200],z=z[:200],text=sample[:200]) #we are considering only 200 words otherwise the plot will be a mess\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr1QqmH9YHlL"
      },
      "source": [
        "Let's extend the random set of terms with a set of colours to see if they cluster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "K_z7NLqgYHlL"
      },
      "outputs": [],
      "source": [
        "# Add some specific terms to sample:\n",
        "colours = ['red','green','blue','orange','yellow','purple','pink','cream','brown','black','white','gray']\n",
        "\n",
        "word_vectors = model.wv[colours+sample]\n",
        "\n",
        "tsne = TSNE(n_components=3)\n",
        "tsne_embedding = tsne.fit_transform(word_vectors)\n",
        "\n",
        "#we see how  these specific words are placed in the compression way\n",
        "\n",
        "x, y, z = np.transpose(tsne_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "fOBvqtDE-HZL",
        "outputId": "a390e4e3-3a6b-40ef-e251-7b1fa7d75715"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"cd237aab-5471-4ec3-bb84-b49a1264ae91\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cd237aab-5471-4ec3-bb84-b49a1264ae91\")) {                    Plotly.newPlot(                        \"cd237aab-5471-4ec3-bb84-b49a1264ae91\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>z=%{z}<br>text=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"line\":{\"width\":2},\"size\":3},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"red\",\"green\",\"blue\",\"orange\",\"yellow\",\"purple\",\"pink\",\"cream\",\"brown\",\"black\",\"white\",\"gray\",null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],\"x\":[-33.95936584472656,-39.10401916503906,-37.566219329833984,-29.34950828552246,-27.79684066772461,20.806161880493164,-13.332945823669434,-6.101837158203125,-34.766197204589844,-30.31383514404297,-23.954078674316406,-29.72229766845703,-27.10409927368164,-5.496267795562744,20.50070571899414,19.031646728515625,1.0875537395477295,-22.08574676513672,2.0453341007232666,18.222259521484375,24.180736541748047,10.838285446166992,-9.350968360900879,43.89075469970703,-28.015480041503906,38.594696044921875,9.92699146270752,-37.44123840332031,-30.58961296081543,-36.2409553527832,-39.755611419677734,-27.189064025878906,-13.930134773254395,17.501296997070312,17.794891357421875,-0.6431630849838257,20.371294021606445,29.387678146362305,35.52768325805664,15.827582359313965,-19.689977645874023,36.882408142089844,-37.664981842041016,-10.762136459350586,-20.402719497680664,32.217803955078125,-34.917640686035156,19.74441909790039,51.503700256347656,32.689849853515625,-24.59296989440918,-16.071901321411133,1.3645902872085571,-18.21721839904785,10.32148551940918,19.97083282470703,14.884336471557617,6.426450729370117,-7.386285305023193,-13.634441375732422,23.473827362060547,40.881675720214844,23.874948501586914,-8.059659957885742,-31.68214988708496,-43.052734375,24.871562957763672,13.924290657043457,-27.805065155029297,-3.527229070663452,22.34967803955078,-15.802519798278809,6.347087860107422,-33.85798645019531,46.08501434326172,4.80864953994751,37.5893440246582,12.59546947479248,-5.565480709075928,32.1634407043457,42.317420959472656,2.7262582778930664,-26.429540634155273,-13.522459030151367,-15.970745086669922,27.47086524963379,-32.97135925292969,-4.402722358703613,-5.422613143920898,-29.877138137817383,-25.063173294067383,6.592393398284912,-22.731136322021484,5.716349124908447,11.319643020629883,22.780136108398438,-23.191755294799805,-42.46647644042969,31.917543411254883,7.684244632720947,5.736275672912598,-1.6040771007537842,-0.5288655161857605,12.091449737548828,-13.367878913879395,-6.987661838531494,-21.760330200195312,-24.50497055053711,11.597198486328125,-34.366058349609375,30.11193084716797,-16.16270637512207,40.5448112487793,13.653630256652832,-31.55275535583496,-20.862232208251953,-14.099784851074219,-25.920806884765625,24.94210433959961,9.333122253417969,8.324263572692871,-23.759315490722656,10.230063438415527,12.651679992675781,-21.646469116210938,14.252270698547363,-13.046359062194824,1.1825706958770752,18.881336212158203,-33.462711334228516,-5.298037052154541,17.350688934326172,30.816049575805664,-8.277420043945312,39.64497756958008,-22.214813232421875,-6.093376159667969,21.28697395324707,7.341853141784668,-6.939340114593506,-17.018579483032227,-20.257747650146484,18.469396591186523,-2.7599761486053467,14.470170021057129,10.300647735595703,-1.218152642250061,-16.847461700439453,19.3475341796875,20.314687728881836,-6.86025333404541,-19.364622116088867,-24.559783935546875,29.63947868347168,-17.394020080566406,6.625395774841309,-20.90390968322754,-26.073305130004883,-26.34892463684082,28.212942123413086,-26.114110946655273,-34.75779342651367,35.57783126831055,30.110919952392578,37.62919616699219,35.41185760498047,-14.971120834350586,-10.428701400756836,26.730812072753906,23.907085418701172,-26.012733459472656,-7.687386512756348,5.685187816619873,-40.489013671875,31.249561309814453,6.4601616859436035,24.575849533081055,-38.59733963012695,19.764854431152344,-14.750117301940918,43.03236389160156,44.16197967529297,-23.33883285522461,35.5335807800293,21.05048179626465,-5.48563814163208,-31.841474533081055,25.520200729370117,11.217340469360352,0.42837637662887573,-15.700851440429688,-29.24797248840332,-43.53914260864258,6.09888219833374,33.82942199707031,22.836397171020508,22.362348556518555,-10.810306549072266,6.970546245574951,29.502029418945312,3.395439624786377,19.664533615112305,10.131229400634766,-0.31981778144836426,16.253244400024414,-1.4249818325042725,-2.0129661560058594,37.15319061279297,-6.9064106941223145,11.407354354858398,4.138207912445068,-3.0342793464660645,-10.98354721069336,44.18457794189453,25.766664505004883,0.4480530321598053,25.099411010742188,9.330669403076172,-14.307273864746094,-29.953123092651367,-32.51983642578125,15.647805213928223,-12.447981834411621,-9.12399959564209,-21.64676284790039,-5.466375827789307,19.28605079650879,-37.758235931396484,9.473241806030273,0.6658617258071899,-16.6646785736084,-37.856964111328125,-9.422247886657715,16.02117156982422,-10.625349998474121,3.0143659114837646,34.70998001098633,10.100627899169922,3.8499221801757812,-38.74226379394531,31.2005558013916,34.996089935302734,-20.414939880371094,22.701101303100586,31.203990936279297,31.717639923095703,7.960118293762207,-12.545371055603027,2.818527936935425,38.79279327392578,-3.3673653602600098,-2.6699323654174805,2.7903406620025635,7.965559959411621,12.00292682647705,27.494749069213867,-2.8558695316314697,-21.02027130126953,-17.81085777282715,37.8004264831543,-42.50798034667969,28.345046997070312,13.077082633972168,24.701889038085938,-26.72814178466797,17.63602066040039,11.904278755187988,2.8374433517456055,20.381696701049805,40.18843078613281,-25.14980125427246,-27.577632904052734,32.594120025634766,-17.675064086914062,-8.72885799407959,-10.321738243103027,14.060908317565918,27.713376998901367,17.112186431884766,34.047515869140625,-34.319496154785156,1.3389759063720703,-31.481367111206055,46.195011138916016,-32.82967758178711,-7.054264068603516,-24.139436721801758,30.491397857666016,23.52520179748535,-7.087233543395996,-19.080745697021484,25.61403465270996,16.56552505493164,16.98750877380371,-24.206640243530273,-8.51938247680664,-34.14946746826172,11.95171070098877,14.277563095092773,1.3493385314941406,-10.127080917358398,-20.4139461517334,-25.305423736572266,-3.2456398010253906,-2.2315497398376465,6.145096302032471,30.874242782592773,-18.478883743286133,-6.789631366729736,0.5203078389167786,-1.2625733613967896,8.412216186523438,3.2017934322357178,41.273895263671875,-7.60244607925415,-31.557138442993164,-2.4683589935302734,14.48468017578125,12.860061645507812,-32.899986267089844,2.656360149383545,-9.299753189086914,6.273694038391113,-4.082891941070557,-43.34611511230469,-2.6705987453460693,-3.653048515319824,-16.66298484802246,-18.3839111328125,-0.8322219252586365,-28.304840087890625,-24.362369537353516,-8.679241180419922,-27.13643455505371,38.411319732666016,40.930606842041016,3.0879147052764893,-36.789947509765625,-13.905010223388672,0.6411451101303101,-38.75368881225586,34.87883758544922,-25.799314498901367,13.572333335876465,3.2266013622283936,-7.151646137237549,28.75930404663086,13.887670516967773,-2.2291855812072754,-24.97694206237793,-34.62577819824219,28.984825134277344,24.78148651123047,18.241912841796875,1.0004115104675293,34.1471061706543,-22.880460739135742,6.552886962890625,12.75258731842041,-11.330875396728516,-13.074524879455566,-11.254952430725098,18.51506805419922,13.257243156433105,2.8396968841552734,39.420413970947266,-6.318728446960449,-2.384798526763916,-14.941417694091797,38.464927673339844,0.6864036917686462,-21.882076263427734,-26.119138717651367,-26.521272659301758,28.786684036254883,-18.32598114013672,23.293601989746094,-14.937674522399902,23.394332885742188,-34.831268310546875,-9.000652313232422,-13.268953323364258,8.924347877502441,26.464000701904297,-14.519676208496094,-34.29264831542969,8.818473815917969,11.587197303771973,-18.67478370666504,-8.212228775024414,6.041345119476318,6.966117858886719,-39.98314666748047,-36.973297119140625,-14.540534019470215,39.779273986816406,28.08075714111328,-19.165952682495117,-22.668542861938477,40.687477111816406,-27.154064178466797,4.128532409667969,4.276252746582031,-33.28822326660156,-4.3479228019714355,-15.952622413635254,7.6107635498046875,-21.313491821289062,-12.2652006149292,-6.791462421417236,10.806777000427246,4.63097620010376,1.177757740020752,17.06053924560547,-9.965723991394043,16.98227882385254,2.786280632019043,23.822433471679688,-5.149820327758789,48.197330474853516,-39.51409149169922,-23.73668098449707,-40.46670913696289,-21.370723724365234,-23.612262725830078,-31.589170455932617,17.2186222076416,-5.863291263580322,-15.961511611938477,-0.8856754899024963,1.1711078882217407,3.9958949089050293,-8.370465278625488,-20.82528305053711,30.265275955200195,-8.842643737792969,-20.67694091796875,-42.50455856323242,-16.063199996948242,-31.557289123535156,28.920644760131836,-12.49930477142334,29.939958572387695,21.36148452758789,13.508028984069824,23.194015502929688,4.453982353210449,-25.76983642578125,-38.59461212158203,15.240365028381348,17.189655303955078,29.459943771362305,-15.288908004760742,31.597326278686523,-0.13156689703464508,-29.3912296295166,-4.130227565765381,-19.683443069458008,-9.176384925842285,3.5705883502960205,22.856239318847656,-36.77010726928711,9.213824272155762,22.067909240722656,16.25429344177246,33.694847106933594,-7.956236839294434,-5.6124420166015625,-17.109556198120117,11.85122013092041,-7.663327693939209,-3.4491066932678223,-24.52825164794922,45.01303482055664,7.905284881591797,-29.36142349243164,46.49833679199219,28.225658416748047,-26.60131072998047,-7.669374942779541,-21.69758415222168,-13.430849075317383,-5.8049845695495605,-33.30469512939453,-16.065793991088867,31.103010177612305,-12.249911308288574,-14.717411994934082,4.073202610015869,-37.70801544189453,-28.075210571289062,38.19845962524414,-42.34097671508789,-35.110252380371094,11.927173614501953,40.043678283691406,2.121464967727661,28.06983757019043,16.092670440673828,16.89558982849121,17.85986328125,-34.971458435058594,-18.842514038085938,-34.050045013427734,-28.539209365844727,-6.393271446228027,33.39252853393555,-10.188972473144531,8.446687698364258,1.8534644842147827,-17.641929626464844,41.524497985839844],\"y\":[19.912817001342773,19.684837341308594,20.946535110473633,13.017993927001953,9.174736022949219,21.855030059814453,-6.323830604553223,-2.2318525314331055,10.370715141296387,22.1350154876709,0.9666287302970886,-21.6024227142334,-18.72854995727539,1.251630425453186,-5.855682373046875,-12.126677513122559,-5.138273239135742,14.838184356689453,-9.859671592712402,-17.013824462890625,3.442202091217041,8.523088455200195,15.740246772766113,5.147182941436768,-5.8794636726379395,-19.664165496826172,2.44547700881958,5.471506595611572,-1.8118704557418823,-9.212440490722656,-15.083792686462402,19.52018928527832,6.246864318847656,-11.343902587890625,13.260357856750488,6.062473297119141,-0.18216244876384735,16.84370994567871,10.538834571838379,-5.837026119232178,18.141611099243164,13.209521293640137,1.9187917709350586,10.067588806152344,1.4812833070755005,-8.601978302001953,-21.544260025024414,11.89479923248291,5.369649887084961,24.841310501098633,10.577219009399414,23.44657325744629,4.267834186553955,-27.136003494262695,-7.975633144378662,0.7725571393966675,28.739566802978516,8.885507583618164,-14.606982231140137,-0.30547747015953064,-2.642181158065796,16.394939422607422,14.660188674926758,-14.034497261047363,-16.541372299194336,5.907015323638916,8.696686744689941,15.213081359863281,13.054490089416504,-3.582430362701416,5.856565952301025,-21.68699073791504,-12.073822021484375,-7.244991302490234,13.967986106872559,-1.0006954669952393,-9.655781745910645,7.6283955574035645,22.909564971923828,-11.984230041503906,-0.9833385944366455,-30.208269119262695,13.74663257598877,-18.819316864013672,-11.249260902404785,2.5518457889556885,-2.167269229888916,13.664835929870605,11.020359992980957,8.54936695098877,14.992291450500488,-24.91254997253418,5.93377161026001,9.362733840942383,-1.1638597249984741,-6.949213027954102,-7.0376081466674805,-8.506261825561523,4.942536354064941,-1.7108992338180542,4.973216533660889,-5.757108688354492,-13.90621566772461,-16.239397048950195,17.586233139038086,8.254806518554688,-5.349844932556152,6.612824440002441,-6.495182991027832,5.555447578430176,-16.108388900756836,0.0010341627057641745,18.682323455810547,22.901905059814453,1.1064523458480835,-14.663444519042969,5.2949724197387695,23.986642837524414,5.4783711433410645,8.381126403808594,13.024127006530762,-9.73990535736084,-13.037007331848145,-13.685165405273438,3.416086196899414,-17.63066864013672,0.9807724356651306,0.19459295272827148,25.560871124267578,-4.220698356628418,-26.579662322998047,7.975780010223389,2.0823817253112793,17.2608585357666,6.173617839813232,-25.696441650390625,-23.178821563720703,-22.554935455322266,24.08599281311035,13.92098617553711,5.516027927398682,-3.0738258361816406,14.859687805175781,-27.377817153930664,1.7755002975463867,13.401321411132812,-9.157733917236328,5.138344764709473,6.837958812713623,3.1230030059814453,-32.73310852050781,0.21497562527656555,8.13503360748291,-10.273226737976074,22.47634506225586,-6.491448402404785,10.721956253051758,-1.0718129873275757,6.540571212768555,-18.60521125793457,9.806048393249512,7.770937919616699,20.37255859375,11.696409225463867,-19.151506423950195,-1.603546142578125,13.357638359069824,-25.73932647705078,13.389396667480469,-5.708934307098389,7.639893531799316,-7.643411636352539,3.946861743927002,-5.430814266204834,1.0139245986938477,-4.9000372886657715,21.92177391052246,11.119532585144043,14.93053913116455,-27.30975914001465,-6.374967575073242,0.9567959904670715,-16.940475463867188,6.283772945404053,-11.641891479492188,-19.84430694580078,-0.10466687381267548,11.19968318939209,14.585417747497559,8.812054634094238,5.530527114868164,-19.752134323120117,7.8175530433654785,4.8216962814331055,-17.51715850830078,11.15350341796875,-1.3828080892562866,-12.180628776550293,-19.966522216796875,18.89769744873047,12.821367263793945,9.263242721557617,3.237562894821167,5.573925018310547,-7.849742412567139,-6.029882907867432,-10.929533958435059,-0.029881469905376434,-16.977670669555664,3.613192081451416,-39.70132064819336,-20.973962783813477,-1.9357715845108032,7.8196001052856445,6.040624141693115,-39.06678771972656,6.380215167999268,-34.53883361816406,-9.190522193908691,-11.55867862701416,1.807043433189392,6.096144676208496,-31.90842056274414,0.8639636635780334,-10.9336519241333,-27.552080154418945,0.10091374814510345,7.011661529541016,-21.777212142944336,-21.125160217285156,-19.573047637939453,13.075647354125977,-19.497577667236328,-24.05883026123047,10.812195777893066,18.99832534790039,-26.282936096191406,-10.32706356048584,-0.10362647473812103,-7.924404621124268,-10.073979377746582,0.8119521141052246,-24.763904571533203,1.0400207042694092,6.503368854522705,-19.116121292114258,13.20570182800293,-15.187337875366211,6.603388786315918,14.615643501281738,-32.779232025146484,7.328973293304443,13.335066795349121,-22.965492248535156,15.069892883300781,24.999671936035156,7.1814775466918945,19.527652740478516,-24.05126953125,12.032482147216797,11.594010353088379,10.318039894104004,-3.9478659629821777,13.231432914733887,10.197562217712402,13.68916130065918,8.689831733703613,21.22303581237793,11.8129301071167,-3.3536365032196045,-21.94685173034668,2.9098618030548096,2.554778575897217,-14.064358711242676,10.836862564086914,-27.821016311645508,21.114065170288086,4.304189682006836,3.0590322017669678,-15.252246856689453,13.924821853637695,-15.724536895751953,4.769815444946289,-5.520493507385254,22.959562301635742,-0.06146879494190216,-0.8387088775634766,11.753360748291016,-2.9662249088287354,16.093671798706055,-15.649055480957031,8.997547149658203,-18.938570022583008,17.70536994934082,-10.75825309753418,-0.46861040592193604,-8.773911476135254,-20.013383865356445,-0.03088819421827793,16.275182723999023,-5.414064407348633,-28.465883255004883,-14.3931884765625,23.10325050354004,-32.3470573425293,-35.258331298828125,12.628503799438477,26.471908569335938,13.57353401184082,20.894100189208984,9.51877498626709,-13.976645469665527,16.010330200195312,10.688652038574219,-7.418079376220703,-22.53363800048828,-7.817017078399658,17.170257568359375,4.74416971206665,-4.904124736785889,-0.4503454864025116,2.545015335083008,-6.876045227050781,2.438483476638794,13.004096984863281,-11.69250774383545,0.09196993708610535,-12.978921890258789,-2.423879623413086,-27.1793212890625,-15.986648559570312,-4.3043060302734375,-6.508111953735352,12.496782302856445,0.3777649998664856,2.9114248752593994,-10.537692070007324,6.375410079956055,29.860187530517578,3.725001573562622,-4.2665696144104,9.745569229125977,19.070343017578125,6.873660564422607,-2.0524656772613525,-11.697396278381348,18.661470413208008,-15.690743446350098,-14.580559730529785,-8.478631019592285,-10.953193664550781,9.34029769897461,18.558855056762695,-0.06866814196109772,12.651694297790527,-16.433490753173828,-9.895267486572266,2.33784556388855,-2.8678061962127686,-8.284589767456055,25.909584045410156,-14.4559326171875,2.3914291858673096,-20.545791625976562,-16.588481903076172,20.310142517089844,17.974721908569336,-5.407761096954346,-7.613638401031494,16.45425796508789,15.120052337646484,15.315652847290039,-9.581578254699707,7.440269470214844,25.88313865661621,16.421340942382812,21.092395782470703,13.650777816772461,18.765039443969727,19.340557098388672,5.781388759613037,-24.450090408325195,-4.035248279571533,8.760334968566895,-8.38839054107666,12.801774978637695,3.2031073570251465,20.072221755981445,-5.408402442932129,20.566776275634766,-6.147514820098877,4.919423580169678,16.206390380859375,-21.195528030395508,13.75622272491455,-17.847810745239258,-0.9111104607582092,8.276633262634277,4.364047050476074,-10.17282772064209,-18.428722381591797,-23.365720748901367,9.15074348449707,17.50983238220215,17.607553482055664,-9.142732620239258,-21.86600112915039,-22.052169799804688,-9.833521842956543,-18.01763153076172,16.126827239990234,-6.286632537841797,2.508131742477417,1.094045639038086,-7.575549125671387,22.493906021118164,23.60557746887207,16.920766830444336,-15.698930740356445,2.489551305770874,-12.722723007202148,5.0815043449401855,11.251643180847168,-4.411704063415527,0.4372769296169281,7.743529319763184,8.25351333618164,-2.2707064151763916,-12.798871040344238,1.5291132926940918,-12.04307746887207,-21.35016441345215,1.2058110237121582,-14.70209789276123,14.351266860961914,-22.034616470336914,-16.793563842773438,0.9922202229499817,9.073969841003418,5.136697292327881,16.499086380004883,0.27211254835128784,25.124004364013672,8.227550506591797,-13.97258186340332,17.35954475402832,-13.336054801940918,-6.370473861694336,-10.880125999450684,0.9980897307395935,8.461020469665527,-10.317620277404785,3.057903289794922,-5.587632179260254,-3.3056857585906982,-1.0307660102844238,4.538102149963379,11.762998580932617,8.231959342956543,1.1664578914642334,11.647222518920898,-18.2026309967041,11.162113189697266,-13.918347358703613,-3.027634620666504,4.303929805755615,-27.266620635986328,-30.37180519104004,2.348301887512207,8.191433906555176,10.635527610778809,-0.13227665424346924,-11.113786697387695,-14.265608787536621,-8.765684127807617,-13.8388090133667,7.89837121963501,21.42245864868164,0.6627857685089111,-0.7913636565208435,13.288734436035156,20.732492446899414,-9.974727630615234,27.637847900390625,-7.1856842041015625,-1.2819311618804932,11.132392883300781,-32.484352111816406,-25.03879165649414,-18.695205688476562,13.319567680358887,-14.943434715270996,-6.2140350341796875,-7.802013397216797,9.294496536254883,-13.546736717224121,1.8649184703826904,27.654966354370117,-7.217607498168945,-13.858403205871582,14.602903366088867,12.920873641967773,17.254148483276367,13.775134086608887,-11.495329856872559,5.6114630699157715,2.6290135383605957,5.235427379608154,-3.6065194606781006,-35.366912841796875,8.560647010803223,8.488008499145508],\"z\":[21.615291595458984,15.030555725097656,18.383703231811523,7.749544620513916,-13.375931739807129,-1.4883332252502441,3.8316123485565186,-14.092547416687012,24.858274459838867,18.10665512084961,31.013591766357422,-10.881125450134277,-8.962465286254883,-13.507612228393555,4.032842636108398,-4.567318439483643,-17.298982620239258,10.77635669708252,-31.724279403686523,-14.392184257507324,6.90523099899292,-5.636194705963135,-3.082320213317871,-5.365654468536377,28.318681716918945,2.1557488441467285,-1.4218193292617798,10.552481651306152,1.5824248790740967,10.859419822692871,-9.691575050354004,-3.1369967460632324,5.864583492279053,14.064217567443848,-5.104058742523193,18.06487274169922,15.890936851501465,1.921036720275879,-3.5813138484954834,-18.494691848754883,0.525102972984314,0.24708513915538788,2.0574519634246826,0.14122526347637177,-7.074125289916992,-11.9433012008667,-0.32234615087509155,11.68520450592041,-5.943789482116699,5.506865978240967,4.657862663269043,-4.464273452758789,25.6776180267334,-3.915498733520508,21.12201499938965,-7.763510704040527,0.18528716266155243,12.941761016845703,10.709428787231445,10.59129810333252,10.183615684509277,5.261162757873535,-8.424654960632324,5.485793590545654,-7.640117168426514,14.586196899414062,-17.476125717163086,8.028936386108398,15.176959991455078,18.00655746459961,12.88022518157959,1.0791367292404175,9.57442569732666,-19.159082412719727,-4.7925944328308105,-7.804832458496094,-6.884428977966309,-27.303939819335938,0.07571102678775787,-9.407670021057129,-5.453114986419678,14.713873863220215,1.3807108402252197,18.76683235168457,-2.6869874000549316,22.775436401367188,9.537992477416992,-10.438889503479004,7.778292179107666,16.49656105041504,-7.233604907989502,5.458890914916992,12.932594299316406,-0.0679442286491394,-14.986430168151855,-7.019676208496094,-23.494821548461914,1.5570651292800903,-2.574096202850342,18.679576873779297,4.215144634246826,6.995863914489746,19.019624710083008,-12.981907844543457,-6.870211124420166,27.113895416259766,29.98802375793457,-16.77945899963379,-13.516934394836426,7.250569820404053,-6.870040416717529,0.5525290369987488,-17.624486923217773,-15.955450057983398,13.584814071655273,11.351113319396973,32.53737258911133,7.928015232086182,-21.470449447631836,-20.15371322631836,-16.53669548034668,5.1051344871521,20.60206413269043,1.632102608680725,4.210785388946533,-24.210302352905273,-10.1660795211792,15.202595710754395,8.06333065032959,27.346298217773438,-20.652973175048828,6.979647159576416,-10.455445289611816,4.81533670425415,-3.449476480484009,-0.42394885420799255,-6.909773349761963,-14.756097793579102,-6.65807580947876,-14.897164344787598,26.8952693939209,27.210556030273438,1.5116554498672485,25.63732147216797,3.864964008331299,22.696889877319336,-3.9839303493499756,-5.320062637329102,2.7206406593322754,-13.44566822052002,2.0410354137420654,7.011136054992676,-24.304147720336914,-2.9570603370666504,4.69256591796875,-26.394683837890625,-2.7194466590881348,11.078926086425781,7.459555625915527,-0.8925549983978271,24.324064254760742,20.347057342529297,-11.83293628692627,-9.07950496673584,-4.609719753265381,-3.50913667678833,2.2934505939483643,28.434669494628906,-2.361254930496216,-15.530708312988281,-6.643857955932617,4.132391929626465,28.512842178344727,-20.52583885192871,-24.380277633666992,5.111711502075195,-22.19157600402832,9.939598083496094,-25.168058395385742,16.3763427734375,-3.320791006088257,-0.08818896859884262,-5.7645158767700195,4.5643792152404785,-23.087251663208008,15.483144760131836,-8.856538772583008,5.280672073364258,1.3832005262374878,24.35097885131836,0.34559884667396545,9.222150802612305,7.716279029846191,-11.116161346435547,4.023895740509033,-0.5054605007171631,-23.785192489624023,2.3919765949249268,7.334616184234619,-5.841882705688477,-22.297391891479492,-21.319673538208008,-16.200620651245117,-5.297560691833496,-25.03789710998535,-22.496612548828125,23.3045597076416,18.219070434570312,-9.09792709350586,-10.29653263092041,-13.44057559967041,10.092306137084961,-6.5572285652160645,-12.862528800964355,-0.013873027637600899,-9.786689758300781,-8.429800033569336,-7.027647972106934,-6.543811798095703,-3.3285365104675293,23.32135009765625,-15.9987154006958,-4.257553577423096,16.631162643432617,-8.520482063293457,-4.84848690032959,-29.679195404052734,4.390269756317139,-11.087858200073242,16.069242477416992,-13.00667953491211,4.78361701965332,6.287142753601074,-4.776700019836426,22.61136817932129,10.008430480957031,-1.1634441614151,-20.34417152404785,-1.6557961702346802,-9.773992538452148,-25.2226619720459,-13.012714385986328,10.449153900146484,0.8218675255775452,-10.624055862426758,-9.99292278289795,-10.030967712402344,-3.62292742729187,-15.912607192993164,-17.790367126464844,2.6408307552337646,1.6456269025802612,-3.596201181411743,24.46159553527832,-3.38557767868042,-19.288190841674805,-22.099180221557617,24.284425735473633,19.49166488647461,9.064872741699219,2.2467308044433594,10.54293155670166,-4.865481853485107,-22.285184860229492,11.427613258361816,-18.973337173461914,-12.583669662475586,-15.764517784118652,6.051111698150635,-10.609273910522461,7.800370216369629,2.2431893348693848,15.858529090881348,5.8241095542907715,17.914201736450195,19.7482852935791,-7.020526885986328,-15.432461738586426,-2.7576348781585693,-3.7002384662628174,1.6116238832473755,6.198525905609131,-5.873394966125488,0.0364956371486187,25.948837280273438,-26.922718048095703,-0.8649997115135193,1.3665322065353394,-11.274417877197266,-8.353203773498535,-15.862305641174316,-27.106660842895508,-6.392429351806641,13.249055862426758,28.912561416625977,3.25850510597229,-14.721715927124023,11.482738494873047,-9.531699180603027,-12.69677448272705,-2.736464500427246,5.89222526550293,16.32526397705078,-7.119261264801025,-16.355148315429688,-11.269068717956543,-21.255422592163086,-2.4873507022857666,1.0476007461547852,-2.6565749645233154,14.89992618560791,-5.154947757720947,3.1856489181518555,-5.349550724029541,12.600719451904297,3.016111373901367,-15.522618293762207,-25.49437713623047,14.740546226501465,20.986032485961914,-13.483631134033203,25.545814514160156,-15.351444244384766,15.901288986206055,12.88840103149414,12.96851634979248,6.077935218811035,24.860065460205078,-14.650303840637207,15.737687110900879,-1.9845023155212402,19.616867065429688,-17.457229614257812,26.70913314819336,-19.22913360595703,-9.004240036010742,1.1351776123046875,-2.792971611022949,-0.5179303288459778,10.050904273986816,-15.37252140045166,-13.162439346313477,7.132481575012207,23.7365665435791,6.009759426116943,-12.534334182739258,-24.936338424682617,-9.186125755310059,-19.931400299072266,15.19895076751709,-9.050247192382812,16.6005802154541,-17.73798942565918,21.65330696105957,11.129525184631348,-14.64846134185791,-19.590293884277344,-28.88011360168457,9.592647552490234,21.55759048461914,-8.883134841918945,16.372146606445312,9.009203910827637,-18.626983642578125,9.764110565185547,-3.447488784790039,-18.904056549072266,-2.2819764614105225,-13.981194496154785,-7.8296709060668945,-7.020302772521973,26.41909408569336,-6.276910781860352,33.39719772338867,4.879559516906738,-12.658947944641113,-7.421783447265625,-4.089825630187988,7.657176494598389,5.273710250854492,14.982523918151855,-3.1597912311553955,-20.62624740600586,21.822267532348633,10.588671684265137,-2.8757011890411377,14.873760223388672,2.1810269355773926,14.153290748596191,8.64211654663086,-4.193860054016113,-5.297045707702637,7.5341105461120605,-4.487516403198242,9.915328025817871,8.121149063110352,-4.610321998596191,-20.962966918945312,-19.997539520263672,2.1925907135009766,19.242124557495117,-12.361193656921387,-9.52810287475586,29.805360794067383,-3.870037078857422,32.47623062133789,15.094158172607422,-5.252082347869873,33.791954040527344,21.156261444091797,-15.723614692687988,14.304028511047363,-10.02674388885498,-17.430198669433594,-8.81890869140625,-11.277148246765137,5.090372085571289,12.997377395629883,0.4359879493713379,-3.1088998317718506,-3.4891114234924316,-0.9077942967414856,23.332500457763672,7.032779216766357,22.574295043945312,0.5331355929374695,-7.732892036437988,9.920913696289062,15.987504959106445,21.033546447753906,-7.701382637023926,-1.7945643663406372,-18.62958335876465,21.16583824157715,-12.643056869506836,12.865038871765137,0.9865946173667908,9.763782501220703,18.54928207397461,28.412961959838867,7.788886547088623,22.949588775634766,-6.693985462188721,-3.537616729736328,10.700937271118164,0.14704027771949768,-13.265406608581543,-14.1103515625,-18.168731689453125,-22.54256248474121,18.073558807373047,12.998757362365723,14.499682426452637,17.604618072509766,-9.010406494140625,24.16215705871582,-31.336191177368164,-7.453893661499023,-9.258337020874023,-23.281572341918945,-14.46341323852539,-15.420455932617188,15.784774780273438,-12.806835174560547,5.0522847175598145,10.649462699890137,23.773155212402344,16.07156753540039,22.26736068725586,7.453691005706787,-4.078314304351807,-1.8923726081848145,-16.3306884765625,1.5071996450424194,-9.113988876342773,-12.561680793762207,-2.0127780437469482,-2.3054544925689697,-18.17194938659668,30.107553482055664,16.702394485473633,-1.0952669382095337,24.178466796875,26.04944610595703,17.862504959106445,3.7062265872955322,-9.429065704345703,15.887894630432129,23.855947494506836,-10.344426155090332,31.750511169433594,3.485179901123047,-8.620429039001465,29.057390213012695,0.675177812576294,-2.2371997833251953,-18.48671531677246,-10.926348686218262,-11.604106903076172,-18.821176528930664,-10.29798412322998,20.011821746826172,-5.390832424163818,13.020224571228027,-19.697219848632812,5.272822856903076,-6.50229024887085,-3.060380458831787,-9.871848106384277,-12.981012344360352,2.456758499145508,1.071472406387329],\"type\":\"scatter3d\",\"textfont\":{\"size\":10}}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"},\"range\":[-200,200]},\"yaxis\":{\"title\":{\"text\":\"y\"},\"range\":[-200,200]},\"zaxis\":{\"title\":{\"text\":\"z\"},\"range\":[-200,200]}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('cd237aab-5471-4ec3-bb84-b49a1264ae91');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "r = (-200,200)\n",
        "fig = px.scatter_3d(x=x, y=y, z=z, range_x=r, range_y=r, range_z=r, text=colours + [None] * 500)\n",
        "fig.update_traces(marker=dict(size=3,line=dict(width=2)),textfont_size=10)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xBPW2vnYHlM"
      },
      "source": [
        "Note: t-SNE is a stochastic algorithm, so run it a couple of times to see how the visualisation changes.\n",
        "\n",
        "Have a play around with the visualisation to see whether other sets of terms cluster together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UxQIRBLYHlM"
      },
      "source": [
        "## Loading Pre-trained Embedding\n",
        "\n",
        "Instead of learning your own word embeddings from a dataset, it is common to download and make use of pre-trained embeddings that have been learnt on very large corpora. \n",
        "- See this list of models available in gensim: https://github.com/RaRe-Technologies/gensim-data\n",
        "- Note how big some of the models are. A 300 dimensional Word2Vec model trained on Google News (word2vec-google-news-300) is almost 1.7GB!\n",
        "\n",
        "Let's downlaod a couple of the smaller models and have a look at them: \n",
        "- We'll download two GloVe (similar to Word2Vec) based models\n",
        "- each has dimension of 50, but the first has been trained on data from Twitter and the second on data from Wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80lgMVCNYHlM",
        "outputId": "1ea73526-def4-44a5-d904-2fbd37049c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 199.5/199.5MB downloaded\n",
            "[==============================================----] 92.9% 61.3/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "#we can use embeddings representation of a set od document\n",
        "\n",
        "model_twitter = api.load(\"glove-twitter-50\")\n",
        "model_wiki = api.load(\"glove-wiki-gigaword-50\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Bg80kKYHlM"
      },
      "source": [
        "How big are their vocabularies?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0CcjNmIYHlM",
        "outputId": "697614d4-07db-4ecf-b15f-b5f3b642d1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size twitter model:  1193514\n",
            "Vocabulary size wikipedia model:400000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Vocabulary size twitter model:  {len(model_twitter)}\") #very high vocabulary so we have considered a very high number of documents\n",
        "print(f\"Vocabulary size wikipedia model:{len(model_wiki)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zSEKFVjYHlM"
      },
      "source": [
        "Woah, they are big vocabularies! \n",
        "- The twitter one has over a million tokens!\n",
        "\n",
        "Let's have a look at the most similar terms to the word 'puppy' in Twitter embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czJartaDYHlM",
        "outputId": "29792282-4c50-4fd9-a96c-ec4ec1658e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Twitter embedding, most similar words to: puppy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kitten', 0.9134266972541809),\n",
              " ('dog', 0.8790459632873535),\n",
              " ('puppies', 0.8616614937782288),\n",
              " ('doggy', 0.8477217555046082),\n",
              " ('pug', 0.8410165905952454),\n",
              " ('bear', 0.8376337885856628),\n",
              " ('cat', 0.833551287651062),\n",
              " ('kitty', 0.8321102857589722),\n",
              " ('pup', 0.8269115686416626),\n",
              " ('husky', 0.8156434297561646)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "term = 'puppy'\n",
        "print(f'Twitter embedding, most similar words to: {term}')\n",
        "model_twitter.most_similar(term)\n",
        "#we can see that we are very striclty words related to the input word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2Wb68G5RWpj"
      },
      "source": [
        "And in the Wikipedia embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5srhaTuYHlM",
        "outputId": "9863dba3-827e-456d-f5e6-2f3c73a42a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wikipedia embedding, most similar words to: puppy\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('puppies', 0.8058912754058838),\n",
              " ('dog', 0.7754921913146973),\n",
              " ('goat', 0.7691047787666321),\n",
              " ('cat', 0.7625599503517151),\n",
              " ('kitten', 0.7443127036094666),\n",
              " ('retriever', 0.731249988079071),\n",
              " ('rottweiler', 0.724050760269165),\n",
              " ('rabbit', 0.7144317626953125),\n",
              " ('squirrel', 0.7086658477783203),\n",
              " ('bitch', 0.7056955695152283)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "print(f'Wikipedia embedding, most similar words to: {term}')\n",
        "model_wiki.most_similar(term)\n",
        "#we try the same with the embeddings that are generated considering another type of document collection\n",
        "# WE SEE THAT THE EMEBEDDING  REPRESENTATION IS BASED ON DOCUMENTS (SUPERVISED BUT ALT THE SAME TIME UNSEPRIVISED BECUASE WE ARE DON'T WRITE THIS TEXT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ez-9f7DLQpDw"
      },
      "source": [
        "Which embedding is better? \n",
        "\n",
        "Try some other words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmwYaVSiYHlN",
        "outputId": "0387c80e-9707-47ff-9e20-9ffc36641e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Twitter embedding:   [('microsoft', 0.8666837811470032), ('google', 0.8337891697883606), ('samsung', 0.8189260363578796), ('nokia', 0.8133970499038696), ('ipad', 0.806841254234314), ('iphone', 0.806834876537323), ('galaxy', 0.8041617274284363), ('blackberry', 0.7953041791915894), ('android', 0.7887364625930786), ('smartphone', 0.788325846195221)]\n",
            "Wikipedia embedding: [('blackberry', 0.7543067336082458), ('chips', 0.7438644170761108), ('iphone', 0.7429664134979248), ('microsoft', 0.7334205508232117), ('ipad', 0.7331036329269409), ('pc', 0.7217225432395935), ('ipod', 0.7199784517288208), ('intel', 0.7192243337631226), ('ibm', 0.7146540284156799), ('software', 0.7093585133552551)]\n"
          ]
        }
      ],
      "source": [
        "term = 'apple'\n",
        "# term = 'politecnico'\n",
        "print(f'Twitter embedding:   {model_twitter.most_similar(term)}')\n",
        "print(f'Wikipedia embedding: {model_wiki.most_similar(term)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBDEnr-0YHlN"
      },
      "source": [
        "Embedding spaces have interesting geometric properties, where translation between different word vectors caries semantic meaning. \n",
        "- Let's try running the famous analogy: king + (woman - man) = ?\n",
        "- To do that, first generate the resulting word embedding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5cMZiNgYHlN",
        "outputId": "daec7baa-3ac8-44b9-9827-84af792a0525"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.41736597,  0.90427005, -1.0050299 , -0.06202101,  0.4972599 ,\n",
              "        0.80667007, -0.14855   ,  0.80365   , -0.15654   , -0.66973996,\n",
              "        0.23435399,  0.62476003,  0.925871  , -0.97099996,  0.92566   ,\n",
              "        0.89915   , -1.54596   , -0.52625   ,  0.13695401,  0.66199005,\n",
              "        0.48716003,  0.37035006, -0.214214  ,  0.10100999,  0.71358   ,\n",
              "       -2.0874999 , -1.1362001 , -1.14961   , -0.53599   ,  0.27389997,\n",
              "        1.6723    ,  0.02931   , -0.77656007,  0.46056286,  0.34866   ,\n",
              "       -0.05741701,  0.19444   , -0.207748  , -0.73038995, -0.10752001,\n",
              "        0.23554398,  0.96423995, -0.46994   , -0.48727497, -0.25399995,\n",
              "        0.46212995, -0.66081   , -1.9451499 , -0.68797004, -0.49784002],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "vec = model_wiki.get_vector('king') + (model_wiki.get_vector('woman') - model_wiki.get_vector('man'))  \n",
        "vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uYDSjJ7YHlN"
      },
      "source": [
        "- Then look for the most similar vectors to it: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5ZMdc5WYHlN",
        "outputId": "f6be9c34-825d-4e7c-e604-e6dd6d827b75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.8859834671020508),\n",
              " ('queen', 0.8609582185745239),\n",
              " ('daughter', 0.7684512734413147),\n",
              " ('prince', 0.7640699744224548),\n",
              " ('throne', 0.7634970545768738),\n",
              " ('princess', 0.7512727975845337),\n",
              " ('elizabeth', 0.7506489157676697),\n",
              " ('father', 0.7314497232437134),\n",
              " ('kingdom', 0.7296158671379089),\n",
              " ('mother', 0.728001058101654)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model_wiki.similar_by_vector(vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tipFzCPnYHlN"
      },
      "source": [
        "Did it work? \n",
        "- Well, yes if you remove 'king' as an option, then it did!\n",
        "- Note that the most similar vector to the word 'king' was not 'queen' but 'prince', so the analogy is indeed changing the order ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDV5VRzAYHlN",
        "outputId": "1b985a21-92f7-4593-cadf-b182d42a2d7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('prince', 0.8236179351806641),\n",
              " ('queen', 0.7839043140411377),\n",
              " ('ii', 0.7746230363845825),\n",
              " ('emperor', 0.7736247777938843),\n",
              " ('son', 0.766719400882721),\n",
              " ('uncle', 0.7627150416374207),\n",
              " ('kingdom', 0.7542160749435425),\n",
              " ('throne', 0.7539913654327393),\n",
              " ('brother', 0.7492411136627197),\n",
              " ('ruler', 0.7434253692626953)]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "model_wiki.most_similar('king')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Io7Zm6EYHlN"
      },
      "source": [
        "Try it again but with the Twitter based model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m511hj-YHlO",
        "outputId": "c3643621-4677-45c4-d78f-82bcdd79f61c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('stone', 0.7156722545623779),\n",
              " ('woman', 0.7105387449264526),\n",
              " ('meets', 0.7078651189804077),\n",
              " ('queen', 0.7035095691680908),\n",
              " ('king', 0.7032954692840576),\n",
              " ('royal', 0.7007310390472412),\n",
              " ('african', 0.6984354853630066),\n",
              " ('prince', 0.6961740851402283),\n",
              " ('virgin', 0.6757708787918091),\n",
              " ('american', 0.6597097516059875)]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "model = model_twitter\n",
        "vec = model.get_vector('king') + (model.get_vector('woman') - model.get_vector('man'))#thi is the way we implement the traslation (so compute the vector that represents the sematic relation\n",
        "# between the2 words and then apply the same relation to another word in order to fidn the corresponde words\n",
        "model.similar_by_vector(vec)\n",
        "\n",
        "#if the traing model is  very big, the bias seems are reduced <--- NB\n",
        "\n",
        "#TRASH IN TRASH OUT \n",
        "#wiki has a more clean vocabulary, while twitter not (so also for this reason we found an higher vocabulary with respect the wikipedia one)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtEO2LWIYHlO"
      },
      "source": [
        "Doesn't seem that the Twitter model is as good on that analogy. \n",
        "- If you think about the average quality of text on Twitter versus Wikipedia, then that's probably not suprising!\n",
        "\n",
        "Try some other analogies:\n",
        "- What happens to Rome if we subtract Italy and add France?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXzOPQy5YHlO",
        "outputId": "1c432622-a262-4000-e8ee-d06adfad7f15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('paris', 0.8583258390426636),\n",
              " ('france', 0.7889718413352966),\n",
              " ('rome', 0.7432292699813843),\n",
              " ('french', 0.733359158039093),\n",
              " ('prohertrib', 0.7260090112686157),\n",
              " ('vienna', 0.7018851637840271),\n",
              " ('saint', 0.6894371509552002),\n",
              " ('gaulle', 0.6854272484779358),\n",
              " ('geneva', 0.6759128570556641),\n",
              " ('berlin', 0.6560173034667969)]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "A = 'rome'\n",
        "B = 'italy'\n",
        "C = 'france'\n",
        "# C = 'indonesia'\n",
        "model = model_wiki\n",
        "vec = model.get_vector(A) - model.get_vector(B) + model.get_vector(C) \n",
        "model.similar_by_vector(vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeUJZDSTYHlO"
      },
      "source": [
        "Now, **isn't that cool?** ;-)\n",
        "- Try some other countries ...\n",
        "\n",
        "Remember, we are only using the 'small' embeddings of 50 dimensions \n",
        "- you can download and try the bigger ones, some of them with 300 dimensions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stWE8L9GYgRH"
      },
      "source": [
        "## Classifying Tweets with word embeddings\n",
        "\n",
        "Let's try to use the word embeddings as features for a text classifier. \n",
        "- In particular, we'll try the tweet sentiment analysis task from the second session.\n",
        "- First download the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bckvn64GYqCZ",
        "outputId": "9a913354-f496-44a0-fbd5-b74d2be35c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('twitter_samples')\n",
        "\n",
        "#we use the embedding for a classification task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5nOSItcaEa9"
      },
      "source": [
        "Then prepare the dataset: \n",
        "- load the positive and negative tweets\n",
        "- remove emoticons from them\n",
        "- and merge them into a single dataset with class labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "VZBH76pnaTrB"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import twitter_samples\n",
        "\n",
        "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "import re \n",
        "\n",
        "emoticon_regex = '(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\n",
        "positive_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in positive_tweets]\n",
        "negative_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in negative_tweets]\n",
        "\n",
        "tweets_x = positive_tweets_noemoticons + negative_tweets_noemoticons\n",
        "tweets_y = ['positive']*len(positive_tweets) + ['negative']*len(negative_tweets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik6TlpDFa3Pt"
      },
      "source": [
        "Divide the data into train, validation and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "sTDd49KVbC_o"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "temp_x, test_x, temp_y, test_y = train_test_split(tweets_x, tweets_y, test_size=0.2)\n",
        "train_x, valid_x, train_y, valid_y = train_test_split(temp_x, temp_y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1aACZFHc_eg"
      },
      "source": [
        "Now we need to convert the tweets to an embedding representation. \n",
        "- We can do that by computing the sum (or average) of the embedding vectors of the words in the tweet.\n",
        "- To work out how to do that, let's have a look at the first tweet in the dataset, converting it to lowercase and tokenise it on whitespace:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVrlyZrqc_vz",
        "outputId": "efa993ef-6b74-4cdb-d25e-e3308fdb711e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet: 'Smile. Its sunnah \n",
            "\n",
            "# #\n",
            " http://t.co/lEVViELaRV'\n",
            "tokens:  ['smile', 'its', 'sunnah', '', '', 'httptcolevvielarv']\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import re\n",
        "regex = '[' + string.punctuation + ']'\n",
        "\n",
        "print('tweet: \\'' + train_x[10] + '\\'')\n",
        "tokens = re.sub(regex, '', train_x[10].lower()).split()\n",
        "print('tokens: ', tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4eDTr_OkWUQ"
      },
      "source": [
        "- We can get the embedding vectors for the tokens present in the embedding vocabulary as follows: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxgUgjVmkW61",
        "outputId": "08bd7ecd-05ac-4174-8a07-d29b119b6562"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.45864 , -0.24194 ,  0.14636 ,  1.1556  , -0.45323 , -0.028691,\n",
              "         1.5431  ,  0.022711, -1.1888  ,  0.81381 , -0.23536 , -0.39181 ,\n",
              "        -3.621   , -0.84961 , -1.3086  ,  0.74812 , -0.4216  , -0.51921 ,\n",
              "         0.044759, -0.56737 ,  0.20546 ,  0.026383, -0.098557,  1.7648  ,\n",
              "         0.21778 ,  0.47358 , -0.76125 ,  0.32891 ,  0.47759 ,  0.27344 ,\n",
              "        -0.7091  , -0.3156  , -0.12709 , -0.12897 ,  0.49409 ,  0.35549 ,\n",
              "         0.6163  , -0.17153 ,  0.16845 ,  0.62927 , -1.1779  , -0.1643  ,\n",
              "         0.36648 ,  0.2199  , -0.08359 ,  0.026037,  0.33544 , -0.21822 ,\n",
              "         0.078041,  0.10998 ], dtype=float32),\n",
              " array([ 0.17241 ,  0.26922 ,  0.26374 ,  0.28937 ,  0.21224 ,  0.83679 ,\n",
              "         0.59143 ,  0.33152 ,  0.61224 ,  0.2016  , -0.17909 , -0.35602 ,\n",
              "        -5.5834  ,  0.074992, -0.20487 , -0.34744 ,  0.58278 ,  0.051087,\n",
              "        -0.71522 , -0.029575, -0.21952 , -0.15951 , -0.1061  ,  0.61987 ,\n",
              "        -0.30958 ,  0.84672 ,  0.23921 , -0.18319 ,  0.32017 , -0.19759 ,\n",
              "        -0.5842  ,  0.21573 ,  0.18049 , -0.69105 ,  0.4657  ,  0.38744 ,\n",
              "        -0.82898 ,  0.11123 , -0.12498 ,  0.077439, -0.81839 , -0.12842 ,\n",
              "         0.45357 ,  0.13762 , -0.15753 , -0.42533 ,  0.54272 , -0.055167,\n",
              "        -0.19227 ,  0.99975 ], dtype=float32),\n",
              " array([ 0.055279,  0.061374,  0.060061,  0.54674 ,  0.29212 ,  0.55774 ,\n",
              "        -0.11217 ,  0.322   , -0.74656 ,  0.67037 ,  0.047081, -0.5811  ,\n",
              "        -1.4557  ,  0.17948 , -1.9351  , -0.017513, -0.40988 , -0.32424 ,\n",
              "         0.72692 ,  0.25449 , -0.34354 ,  0.51546 , -2.2762  , -0.13982 ,\n",
              "         0.86565 ,  0.39584 ,  0.27924 , -1.022   ,  0.15568 ,  0.33746 ,\n",
              "         0.49993 ,  0.28122 ,  1.0886  , -0.9935  , -0.29083 ,  0.14904 ,\n",
              "        -0.16746 , -0.14415 ,  0.96744 , -0.74618 ,  0.098599, -1.4418  ,\n",
              "        -0.44577 , -1.6141  ,  0.55329 ,  0.64261 , -0.51696 , -0.70518 ,\n",
              "         0.897   , -1.1336  ], dtype=float32),\n",
              " array([-0.24773  , -0.57025  , -1.0058   , -1.549    ,  0.80425  ,\n",
              "         0.32801  , -0.79424  , -1.4169   , -0.0043363,  0.36631  ,\n",
              "         0.54555  , -0.47466  , -0.52754  , -0.8585   , -0.53409  ,\n",
              "         0.37089  , -0.62255  , -1.4911   ,  0.19577  , -0.091898 ,\n",
              "        -2.7419   , -0.93118  ,  1.0165   ,  0.46131  , -0.039473 ,\n",
              "         0.63128  ,  0.29264  , -0.037021 , -0.65657  , -0.33187  ,\n",
              "        -0.72711  , -0.80109  ,  0.75897  , -0.96181  , -1.4063   ,\n",
              "        -0.76356  , -0.10649  ,  0.96974  , -0.049303 , -0.36781  ,\n",
              "         1.5174   , -1.6327   , -0.5043   , -1.2849   , -0.39706  ,\n",
              "        -1.5648   ,  1.6347   ,  0.40179  , -2.2086   , -0.055432 ],\n",
              "       dtype=float32),\n",
              " array([ 1.723    , -1.1851   ,  0.83896  ,  0.61839  ,  0.0057563,\n",
              "         0.43017  , -0.43881  , -0.21144  , -0.51356  ,  1.3642   ,\n",
              "         1.2525   ,  0.61694  ,  2.0079   ,  1.2318   , -0.012766 ,\n",
              "        -1.3438   , -0.32678  ,  0.86504  ,  0.27555  , -0.81616  ,\n",
              "         0.072581 , -0.19735  ,  0.43849  ,  0.11258  ,  0.10526  ,\n",
              "        -0.083757 ,  0.48465  ,  0.21276  ,  0.044132 ,  0.11985  ,\n",
              "        -2.5171   , -1.2167   , -1.2876   ,  1.9626   ,  0.94394  ,\n",
              "         0.47017  ,  0.75549  ,  0.59667  , -0.09971  , -1.1425   ,\n",
              "        -0.65822  , -0.25065  , -0.14497  ,  0.27317  ,  0.134    ,\n",
              "         0.19532  , -0.0040995,  0.4802   , -0.98482  ,  0.6075   ],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "model = model_twitter\n",
        "embeddings = [model.get_vector(token) for token in tokens if token in model]\n",
        "embeddings\n",
        "\n",
        "#we can use the ebedding model to represent the the "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p58DUnpNXenf"
      },
      "source": [
        "- the sum of the embeddings in the tweet is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0uuM4q7sid9",
        "outputId": "4fcaa1fe-c599-41c8-f8e1-920a0c7fa1f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.244319  , -1.666696  ,  0.30332094,  1.0611    ,  0.8611363 ,\n",
              "        2.124019  ,  0.7893101 , -0.952109  , -1.8410163 ,  3.4162898 ,\n",
              "        1.430681  , -1.18665   , -9.17974   , -0.221838  , -3.9954257 ,\n",
              "       -0.58974296, -1.19803   , -1.4184229 ,  0.527779  , -1.2505131 ,\n",
              "       -3.026919  , -0.746197  , -1.0258671 ,  2.81874   ,  0.839637  ,\n",
              "        2.263663  ,  0.53449   , -0.7005409 ,  0.341002  ,  0.20129004,\n",
              "       -4.03758   , -1.83644   ,  0.61337006, -0.8127301 ,  0.20660001,\n",
              "        0.59858   ,  0.26885998,  1.3619599 ,  0.86189705, -1.5497811 ,\n",
              "       -1.038511  , -3.6178699 , -0.27499   , -2.26831   ,  0.04911003,\n",
              "       -1.126163  ,  1.9918004 , -0.09657699, -2.410649  ,  0.528198  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "sum(embeddings) #we can sum the different embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpiF8tQCkZe5"
      },
      "source": [
        "- and the average of the embeddings is just:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld2gtl6ukZty",
        "outputId": "c99c7058-b27e-4558-9f92-e189b0736a48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.24886379, -0.33333918,  0.06066419,  0.21222   ,  0.17222726,\n",
              "        0.4248038 ,  0.15786202, -0.19042179, -0.36820325,  0.68325794,\n",
              "        0.2861362 , -0.23733   , -1.835948  , -0.0443676 , -0.79908514,\n",
              "       -0.11794859, -0.239606  , -0.28368458,  0.1055558 , -0.2501026 ,\n",
              "       -0.60538375, -0.14923939, -0.20517342,  0.563748  ,  0.1679274 ,\n",
              "        0.45273262,  0.10689799, -0.14010818,  0.06820039,  0.04025801,\n",
              "       -0.807516  , -0.367288  ,  0.12267401, -0.16254601,  0.04132   ,\n",
              "        0.119716  ,  0.053772  ,  0.27239197,  0.1723794 , -0.30995622,\n",
              "       -0.2077022 , -0.723574  , -0.054998  , -0.453662  ,  0.00982201,\n",
              "       -0.2252326 ,  0.39836007, -0.0193154 , -0.4821298 ,  0.1056396 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.mean(embeddings, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCvTji3wlpGH"
      },
      "source": [
        "We will need to perform this vector transformation for all tweets in the training and also the test sets\n",
        "- We can define a procedure to do that for us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "uopuAE26d7gH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize(docs, embedding_model=model_twitter, useSum=True):\n",
        "    vectors = np.zeros((len(docs),50))\n",
        "    for i in range(len(docs)):\n",
        "        tokens = re.sub(regex, '', docs[i].lower()).split()\n",
        "        embeddings = [embedding_model.get_vector(token) for token in tokens if token in embedding_model]\n",
        "        if (len(embeddings) > 0):\n",
        "            if (useSum): \n",
        "                vectors[i] = sum(embeddings)\n",
        "            else:\n",
        "                vectors[i] = np.mean(embeddings, axis=0)\n",
        "    return vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WoMOcuFYcbM"
      },
      "source": [
        "Let's now vectorize the training set\n",
        "- and then print out one of the instances to check that the format is correct:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iviol4QhenZx",
        "outputId": "e5f2320d-6d30-4a2d-8143-b2cfd681291d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.31971991e-01,  5.94669938e-01,  6.66069925e-01,\n",
              "        -1.62660301e+00, -1.50954008e+00,  1.21649003e+00,\n",
              "         4.33885002e+00, -4.05380040e-01,  1.09281993e+00,\n",
              "         3.06429100e+00, -1.34367502e+00, -1.17303395e+00,\n",
              "        -2.61487999e+01, -1.13277006e+00, -2.18053007e+00,\n",
              "         1.25238001e+00,  3.74189913e-02, -1.91371012e+00,\n",
              "        -5.15641022e+00, -1.65010202e+00,  6.92013979e-01,\n",
              "         1.01060605e+00,  4.81700987e-01,  2.73959899e+00,\n",
              "        -9.60898936e-01,  1.88012004e+00,  6.90080047e-01,\n",
              "         4.99520004e-02,  2.04699993e+00, -7.89118946e-01,\n",
              "        -8.49545002e-01,  8.22309971e-01, -3.39551806e-01,\n",
              "         1.02381909e+00, -2.02406526e-01,  8.86150002e-01,\n",
              "        -1.67076898e+00, -5.46948016e-01, -4.88991052e-01,\n",
              "         2.82061934e+00, -5.04525995e+00,  1.91710997e+00,\n",
              "         2.29736304e+00,  2.32538986e+00,  9.23950076e-01,\n",
              "        -8.48779082e-01,  2.69035411e+00, -5.47778010e-01,\n",
              "        -2.87489605e+00,  1.20700598e+00],\n",
              "       [ 2.51066780e+00,  8.73141766e+00,  3.21427083e+00,\n",
              "        -7.65611231e-02, -6.08098888e+00, -2.39482117e+00,\n",
              "         1.26512794e+01, -2.28803492e+00,  3.29882383e+00,\n",
              "         1.17219334e+01, -1.06711793e+00, -1.09495366e+00,\n",
              "        -1.03919197e+02,  6.26251101e-02, -4.89857674e+00,\n",
              "        -2.03274584e+00, -1.98703587e+00, -6.61046457e+00,\n",
              "        -6.31805182e+00, -5.50376320e+00,  4.67066622e+00,\n",
              "         2.55420709e+00,  3.64179468e+00,  2.48651123e+00,\n",
              "        -1.71830130e+00,  6.40823078e+00,  2.31451011e+00,\n",
              "         4.76005793e-01,  1.63481617e+00, -9.78743970e-01,\n",
              "        -3.20922208e+00,  4.78514290e+00, -1.87213027e+00,\n",
              "         3.43819886e-01,  1.67483175e+00,  7.08169031e+00,\n",
              "        -1.59461010e+00,  2.04359829e-01, -1.70572305e+00,\n",
              "         5.63389206e+00, -1.50465231e+01,  4.52797842e+00,\n",
              "         4.54186630e+00, -1.62150919e-01, -4.46834058e-01,\n",
              "        -5.76010609e+00,  9.44789219e+00, -6.08145177e-01,\n",
              "        -7.12532091e+00, -2.11502814e+00],\n",
              "       [ 6.69189990e-01,  5.42639971e-01,  2.92959988e-01,\n",
              "        -3.40429991e-01, -8.29270005e-01,  7.68180013e-01,\n",
              "        -1.90880001e+00, -1.09519994e+00, -2.16739997e-01,\n",
              "        -7.99709976e-01,  5.64199984e-01, -8.33780020e-02,\n",
              "        -5.98790012e-02,  1.54149998e-02,  2.44200006e-01,\n",
              "         1.76750004e+00,  1.43229997e+00,  1.09660006e+00,\n",
              "        -6.76750019e-02, -5.97880006e-01, -1.02179997e-01,\n",
              "         4.96339984e-02,  2.43790001e-01,  1.28680003e+00,\n",
              "         4.04170007e-01,  6.27849996e-01,  1.47579998e-01,\n",
              "         2.25510001e-01, -2.50330001e-01, -1.28760004e+00,\n",
              "        -2.25309998e-01, -2.32800007e-01,  5.53330004e-01,\n",
              "        -2.40769997e-01,  6.67360008e-01, -8.79960001e-01,\n",
              "        -8.52289975e-01,  3.50220017e-02, -9.02260005e-01,\n",
              "        -2.77260005e-01, -3.27740014e-01, -2.17869997e-01,\n",
              "        -7.16000021e-01,  1.09430003e+00, -7.65089989e-01,\n",
              "         2.90380001e-01,  9.50259984e-01, -1.12350002e-01,\n",
              "        -3.08939993e-01,  9.95410025e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "train_x_vector = vectorize(train_x)\n",
        "train_x_vector[:3] #they are the sum of the embedding of the first 3 tweets, that are genetaed by summing the different emebeddings presentin in a sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z39a21KpdBHb"
      },
      "source": [
        "Now that we have the vectorized training data, we can go ahead and train the model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCuF581vdBcp",
        "outputId": "9b9f93b5-e3bb-4aa6-f252-7f53cbf31a78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(max_iter=1000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression(max_iter=1000).fit(train_x_vector, train_y)\n",
        "print(lr_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAQhGdw_Yyi1"
      },
      "source": [
        "Let's test the model on the example tweets from the second tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTb8hjCNkBf-",
        "outputId": "a9d87791-d667-4c23-ca22-0fa59c527571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet:      I can't believe how much fun I'm having learning to train a text classifier using word embeddings!\n",
            "prediction: positive\n",
            "confidence: [0.4637625 0.5362375]\n",
            "\n",
            "tweet:      I am really confused. I want my mommy.\n",
            "prediction: negative\n",
            "confidence: [0.85052037 0.14947963]\n",
            "\n",
            "tweet:      The internet connection has been pretty annoying today!\n",
            "prediction: negative\n",
            "confidence: [0.83035396 0.16964604]\n",
            "\n",
            "tweet:      They just played my favourite song on the radio.\n",
            "prediction: positive\n",
            "confidence: [0.44259855 0.55740145]\n",
            "\n",
            "tweet:      I don't like going to the dentist.\n",
            "prediction: negative\n",
            "confidence: [0.87971081 0.12028919]\n",
            "\n",
            "tweet:      Can't wait for my three hour math class tomorrow morning. Yay!\n",
            "prediction: negative\n",
            "confidence: [0.62418574 0.37581426]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tweets = []\n",
        "tweets.append('I can\\'t believe how much fun I\\'m having learning to train a text classifier using word embeddings!')\n",
        "tweets.append('I am really confused. I want my mommy.')\n",
        "tweets.append('The internet connection has been pretty annoying today!')\n",
        "tweets.append('They just played my favourite song on the radio.')\n",
        "tweets.append(\"I don't like going to the dentist.\")\n",
        "tweets.append(\"Can't wait for my three hour math class tomorrow morning. Yay!\")\n",
        "\n",
        "\n",
        "transformed_tweets = vectorize(tweets)\n",
        "predictions = lr_model.predict(transformed_tweets)\n",
        "predicted_probabilities = lr_model.predict_proba(transformed_tweets)\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "  print(f'tweet:      {tweets[i]}')\n",
        "  print(f'prediction: {predictions[i]}')\n",
        "  print(f'confidence: {predicted_probabilities[i]}')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLBJOO8cbVHP"
      },
      "source": [
        "We can have a look at the coefficients of the logistic regression classification model. \n",
        "- How many should there be?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPtPzQuLomrR",
        "outputId": "7a1484df-2371-4e83-c30d-cc6964b8fe6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.99299507e-03, -5.36406437e-03,  2.07503080e-02,\n",
              "        -4.31455925e-02,  2.34037846e-01,  2.51017281e-01,\n",
              "         7.58200276e-02, -1.40425873e-01, -1.05527437e-01,\n",
              "         2.31333993e-02, -1.03903387e-01,  2.44937924e-01,\n",
              "         3.39104858e-02, -3.84766536e-02, -2.16216498e-01,\n",
              "         5.50145015e-02, -1.95404194e-02, -1.05085905e-05,\n",
              "         1.64830771e-01,  3.50429745e-02,  8.22676454e-03,\n",
              "        -6.44281100e-02, -8.48250009e-02, -6.18798994e-02,\n",
              "         6.22126095e-02,  7.20567514e-02,  7.93941692e-02,\n",
              "        -7.23814394e-02,  1.91669332e-01,  6.97072123e-02,\n",
              "         1.61259326e-01,  1.35257720e-01, -4.86097821e-02,\n",
              "         5.63615365e-02,  1.06936013e-01,  1.74427631e-01,\n",
              "         1.52603837e-01,  9.49610104e-02, -9.05596407e-04,\n",
              "        -4.51380800e-02, -5.59729595e-02, -3.89963692e-02,\n",
              "         5.44507014e-02,  1.50634396e-01, -2.34426360e-02,\n",
              "         9.60033424e-02,  4.13123724e-02,  1.42002129e-02,\n",
              "         6.33436506e-02, -4.94775347e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "lr_model.coef_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eso1pS5Ybevo"
      },
      "source": [
        "Let's vectorize the validaton data and see how well the embeddings-based classifier performs on it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "DncyqQpinGHG",
        "outputId": "9825462c-377b-4aba-d82e-fb1a9fb74458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.735\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "valid_x_vector = vectorize(valid_x)\n",
        "pred_y = lr_model.predict(valid_x_vector)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(f'Accuracy: {accuracy_score(valid_y, pred_y)}')\n",
        "\n",
        "import matplotlib.pyplot as plt  \n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "ConfusionMatrixDisplay.from_estimator(lr_model, valid_x_vector, valid_y, values_format='d')  \n",
        "plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z23krami3W0"
      },
      "source": [
        "So pretty much the same accuracy as the bag-of-words based classifier. \n",
        "- but this time with feature vectors of size 50\n",
        "- what happens to the accuracy if we: \n",
        "  - use a different embedding: model_wiki instead of model_twitter\n",
        "  - use a bigger (higher dimensional) embedding: download a larger one to see\n",
        "  - use the average rather than the sum to generate the feature vector?\n",
        "- try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ojy2UOofkQsE"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvWLcBqGkTFO"
      },
      "source": [
        "Also worth trying is doc2vec rather than word2vec embeddings:\n",
        "- in theory they should give slightly better performance on sentence classification tasks\n",
        "- see here: https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIvbxdRpYHlO"
      },
      "source": [
        "## Other uses for Word2Vec embeddings\n",
        "\n",
        "Have a look at this inventive post that learns Word2Vec embeddings for automobiles described in CSV file:\n",
        "- https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92\n",
        "- The embeddings allow for similarity computations across  the vehicles. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YWk4FnIYHlO"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PifwcbdWqKz"
      },
      "source": [
        "## FastText (sub-word) embeddings\n",
        "\n",
        "Try training a fasttext model:\n",
        "\n",
        "https://pypi.org/project/fasttext/\n",
        "\n",
        "You can have a look at the API and documentation at this [link](https://fasttext.cc)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJn_r-pPHxim"
      },
      "source": [
        "Let's start by installing the fastText package.\n",
        "(Note that, alterantively, Genism has a specific API for fastText that wraps the package we are going to use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52qmtcvvKmXD",
        "outputId": "e8b9466d-453e-4309-d166-85543096d761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/68.8 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m68.8/68.8 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from fasttext) (67.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fasttext) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp39-cp39-linux_x86_64.whl size=4395617 sha256=ec63695aceebdb899811504057594a68d43d8bf7454cee6219a4e6c839e4b0c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/57/bc/1741406019061d5664914b070bd3e71f6244648732bc96109e\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.4\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x62UPMmPwTZN"
      },
      "source": [
        "Now that we have installed the package, we can download one of the pre-trained models (you can find here the list of available models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w332B-YpwTjV",
        "outputId": "59be3926-d903-4c55-c5d1-c5246dd1ae90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-29 11:37:17--  http://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 99.84.208.25, 99.84.208.90, 99.84.208.60, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|99.84.208.25|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4503593528 (4.2G) [application/octet-stream]\n",
            "Saving to: cc.en.300.bin.gz\n",
            "\n",
            "cc.en.300.bin.gz    100%[===================>]   4.19G   186MB/s    in 20s     \n",
            "\n",
            "2023-03-29 11:37:37 (216 MB/s) - cc.en.300.bin.gz saved [4503593528/4503593528]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip\n",
        "!wget http://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
        "!gzip -d cc.en.300.bin.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tDcLNT9fKUl"
      },
      "source": [
        "Finally we can create a model istance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrDxcw89fKgr",
        "outputId": "b0990f07-744e-40aa-f559-f33e887cd18b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "\n",
        "ft_model = fasttext.load_model('./cc.en.300.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnpPQ0j3mUiE"
      },
      "source": [
        "What is the size of the vocabulary?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhqskdAimTLa",
        "outputId": "b07c9eb0-8de7-4af0-b347-dffd60724c19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000000"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "len(ft_model.get_words())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19fBomf5mVDU"
      },
      "source": [
        "What is the size of the embeddings?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK9X-b5XmTic",
        "outputId": "23f94579-3851-4a25-a4db-7d326ea4b969"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "ft_model.get_dimension()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eG6JJVaw4-9R"
      },
      "source": [
        "How do we get the embedding of a word?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7BZLizk4-9S",
        "outputId": "0245180c-79e3-46b7-f9aa-00c6e1399c0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.37498349e-01,  1.73652887e-01,  1.55173652e-02,  2.37601340e-01,\n",
              "       -2.04669774e-01,  1.87128603e-01,  2.91468382e-01,  3.73304449e-03,\n",
              "        4.89513204e-02,  2.60247648e-01, -8.31757560e-02, -1.56491295e-01,\n",
              "        8.69184956e-02, -4.78181392e-02, -1.18615523e-01,  1.54884279e-01,\n",
              "       -1.69153258e-01, -1.22394666e-01, -1.40723094e-01,  4.53762040e-02,\n",
              "       -3.81604545e-02, -1.46799475e-01,  1.36863321e-01, -1.50539711e-01,\n",
              "       -1.81618929e-02,  1.47275031e-02, -4.21417244e-02,  1.39445990e-01,\n",
              "        4.28556725e-02,  3.05333138e-01, -1.66591443e-02,  2.91614503e-01,\n",
              "       -3.32667604e-02, -4.68752086e-02,  2.67606732e-02,  8.71477500e-02,\n",
              "       -5.38966954e-02,  1.33774459e-01,  8.50976482e-02, -6.40801638e-02,\n",
              "       -1.03779674e-01, -1.81272849e-01, -1.10902652e-01,  1.66989714e-01,\n",
              "       -1.99763715e-01,  4.53899801e-03, -1.89182535e-02, -2.78699417e-02,\n",
              "       -2.93243110e-01, -5.81464916e-03,  1.75295904e-01,  1.08659819e-01,\n",
              "       -1.88145787e-02,  2.53145359e-02,  9.95914787e-02, -3.12647223e-02,\n",
              "        9.74955484e-02, -1.57494023e-01, -1.64722189e-01, -6.87088072e-02,\n",
              "        9.10460949e-05,  1.59804896e-02,  1.10373735e-01,  6.10446706e-02,\n",
              "        1.07483588e-01, -1.33552194e-01, -7.02596456e-02,  1.16452649e-01,\n",
              "        1.18472248e-01,  6.14816248e-02, -8.17625001e-02,  4.12990153e-03,\n",
              "        1.23452470e-02,  1.57015212e-02,  3.73466015e-02, -1.09414756e-02,\n",
              "       -8.77702013e-02,  2.94106871e-01, -1.09256595e-01, -7.45082274e-02,\n",
              "       -2.63583213e-01, -2.84229126e-02, -1.52215466e-01, -1.00488283e-01,\n",
              "        4.63331118e-02, -6.50667697e-02, -7.57237226e-02,  1.46466196e-02,\n",
              "       -3.01163793e-02, -6.27530664e-02,  7.32356012e-02, -3.39862436e-01,\n",
              "       -2.12151855e-02,  1.20418519e-01,  1.95152871e-02,  1.46374375e-01,\n",
              "        4.19964790e-02,  2.27189422e-01, -4.76691127e-02,  5.83246611e-02,\n",
              "       -1.18166231e-01,  1.94506012e-02,  1.29298002e-01, -8.22782367e-02,\n",
              "       -1.82408914e-01,  1.22837633e-01, -4.33400944e-02, -7.62889758e-02,\n",
              "       -1.49289474e-01,  1.32627741e-01,  2.07074419e-01, -2.40204573e-01,\n",
              "       -3.01707983e-02,  1.00110896e-01,  1.09480068e-01,  1.78128794e-01,\n",
              "        5.19588068e-02, -1.18714668e-01, -6.70131519e-02,  2.07650527e-01,\n",
              "       -3.13496441e-02,  2.84634590e-01, -8.52486044e-02, -2.01036707e-02,\n",
              "       -1.93305723e-02, -2.07597405e-01, -1.20448753e-01,  1.40477762e-01,\n",
              "        1.05674461e-01,  3.88197601e-03,  6.56490326e-02, -2.37631038e-01,\n",
              "       -3.56610008e-02, -8.02731290e-02, -2.24592313e-02, -1.23117693e-01,\n",
              "        1.51049644e-01,  2.43693039e-01,  1.88642144e-01,  3.11025791e-03,\n",
              "       -1.42823428e-01,  7.86538571e-02,  6.08236715e-03, -1.67422846e-01,\n",
              "       -8.55229050e-02,  7.95976892e-02, -3.45605433e-01,  5.82623780e-02,\n",
              "       -1.06225297e-01, -1.78768754e-01, -4.63169813e-02, -7.22998232e-02,\n",
              "        6.99614957e-02, -1.17765516e-02, -1.15494572e-01, -5.82705364e-02,\n",
              "        1.16676003e-01,  5.70290461e-02, -7.90311471e-02,  8.35967138e-02,\n",
              "        8.16148371e-02, -1.73566580e-01,  2.34466106e-01,  3.13998163e-02,\n",
              "       -2.83091217e-02, -3.13015580e-02,  1.57410666e-01, -1.23833120e-02,\n",
              "       -6.04008958e-02,  1.00380607e-01,  1.09081395e-01,  5.35128973e-02,\n",
              "       -1.12907238e-01, -2.18785390e-01, -2.26536058e-02, -2.15117663e-01,\n",
              "       -1.11640386e-01, -3.89714614e-02,  8.59435648e-02, -1.97914347e-01,\n",
              "       -4.17543389e-02, -1.15136296e-01,  4.49582487e-02, -1.30544692e-01,\n",
              "       -6.05523065e-02,  3.08122993e-01, -4.84386310e-02, -5.04352376e-02,\n",
              "        5.67938611e-02,  1.03469603e-01,  3.77609134e-02,  1.75252743e-03,\n",
              "        2.36129127e-02,  1.28008991e-01, -9.24589187e-02, -1.44171059e-01,\n",
              "        3.02452624e-01, -1.20941728e-01,  2.55626217e-02, -4.43983078e-02,\n",
              "        1.31773561e-01,  5.05378768e-02,  4.99319136e-02, -4.53851558e-02,\n",
              "       -1.25326589e-01,  1.03378303e-01,  9.02659371e-02,  8.87431204e-03,\n",
              "        1.90032590e-02,  6.09402731e-02,  8.95207599e-02, -9.70865861e-02,\n",
              "       -9.47063640e-02,  2.91972943e-02, -1.52865816e-02, -1.61617801e-01,\n",
              "        3.19432677e-03, -6.58987164e-02,  6.43858016e-02, -2.62204409e-02,\n",
              "        7.66740441e-02, -3.07367295e-02, -1.66517615e-01, -4.53550480e-02,\n",
              "        1.12862349e-01,  2.02228762e-02, -6.31066635e-02, -2.73563862e-01,\n",
              "       -8.24580714e-02, -7.55187646e-02,  2.45882347e-01,  7.84016699e-02,\n",
              "       -7.31700063e-02, -5.58071174e-02, -2.08459049e-02,  1.32113360e-02,\n",
              "       -1.15614533e-01, -1.28816754e-01, -7.76782110e-02,  1.39297172e-02,\n",
              "        7.68901408e-02,  3.53115499e-02, -7.35836700e-02, -1.48101956e-01,\n",
              "        1.57499254e-01,  2.79525697e-01, -7.00949654e-02, -1.30779624e-01,\n",
              "       -6.56079650e-02, -3.89638245e-02,  2.90693641e-02,  2.53306665e-02,\n",
              "       -1.87344216e-02,  8.13647956e-02,  1.52117580e-01,  5.24173714e-02,\n",
              "       -2.27155939e-01,  3.56054865e-02,  1.05434768e-02, -6.52607605e-02,\n",
              "        9.73352417e-02, -6.46137819e-02, -2.53503621e-02,  1.22090224e-02,\n",
              "       -1.39826387e-01, -7.75838494e-02, -2.07123429e-01, -7.15182126e-02,\n",
              "        8.69591534e-03,  1.41621977e-02, -1.93011254e-01,  2.27474242e-01,\n",
              "       -1.15029059e-01,  4.09493409e-02, -8.25189203e-02, -7.64346272e-02,\n",
              "       -9.39211100e-02,  4.57039848e-02,  2.61136368e-02, -3.34188640e-02,\n",
              "        4.32544090e-02, -1.03707597e-01, -1.41373813e-01, -1.44344121e-01,\n",
              "        1.59042463e-01,  9.89959389e-03,  2.83480138e-02, -2.38574252e-01,\n",
              "       -2.76446074e-01, -8.09888542e-02, -4.18215282e-02,  1.75330192e-02,\n",
              "       -1.65929049e-01,  1.04931220e-01, -1.10928323e-02,  9.20476243e-02,\n",
              "        6.67028055e-02,  2.07736552e-01,  8.53124261e-02, -1.40121192e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "ft_model.get_word_vector('car')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SqN30CY4-9T"
      },
      "source": [
        "Alterantively you can use it as a Python dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq32k0Oo4-9T",
        "outputId": "63a52368-a086-466f-f730-ccbc7f5194e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 2.05102742e-01, -1.17439777e-01, -1.55425537e-02,  1.79349303e-01,\n",
              "       -2.28049219e-01, -1.24558017e-01,  1.23250902e-01,  5.38473055e-02,\n",
              "        4.11795303e-02, -5.67295495e-03, -8.39752406e-02,  1.84653439e-02,\n",
              "       -8.60689804e-02,  1.12930965e-02, -1.33117482e-01,  1.38373390e-01,\n",
              "       -1.25412792e-01, -3.86665910e-02, -1.22192718e-01,  1.07491598e-01,\n",
              "        7.44868889e-02,  1.43000856e-01, -2.68281717e-02,  7.85946473e-03,\n",
              "       -3.62306088e-02, -2.08035931e-02,  9.95780062e-03, -5.96441068e-02,\n",
              "        3.78727615e-02,  1.31439894e-01, -6.71993792e-02,  6.71701431e-02,\n",
              "        1.11701377e-01, -1.82819627e-02, -1.02341630e-01,  9.74911451e-03,\n",
              "        4.25241441e-02, -1.59083098e-01,  3.72390151e-02, -1.32961005e-01,\n",
              "       -6.62351400e-02,  1.17778786e-01, -3.11643854e-02, -4.58469465e-02,\n",
              "       -1.54904723e-01,  2.37882137e-03,  2.09096503e-02, -6.17710687e-03,\n",
              "       -2.41204053e-01,  8.73834118e-02,  6.91391528e-02,  1.11958645e-01,\n",
              "       -1.52415112e-02, -1.00177675e-01, -6.60216436e-02,  7.77632892e-02,\n",
              "        9.00297761e-02,  3.69252376e-02, -2.52914429e-02,  2.36923918e-02,\n",
              "       -1.53724262e-02,  3.27921212e-02, -1.39887005e-01,  1.09796673e-02,\n",
              "        7.74039626e-02, -7.29498342e-02,  3.66372019e-02,  6.94629326e-02,\n",
              "       -4.31373864e-02,  3.86431366e-02, -2.37832926e-02, -2.62797046e-02,\n",
              "       -8.52299929e-02, -1.24506094e-03, -1.66640848e-01, -7.69969672e-02,\n",
              "        1.00765273e-01,  3.93868051e-03,  1.25144869e-02,  1.72688425e-01,\n",
              "       -4.70201746e-02, -7.07887039e-02,  2.69618072e-02,  8.90153423e-02,\n",
              "       -8.63350183e-02,  5.59332669e-02,  6.88511878e-02, -1.81689560e-02,\n",
              "        1.49315774e-01, -2.06480175e-03, -4.99112904e-02,  9.12162587e-02,\n",
              "        6.12079501e-02,  3.40343006e-02, -1.59623727e-01,  9.91314650e-03,\n",
              "        1.47123680e-01,  7.51622468e-02,  1.25847980e-01,  7.28560686e-02,\n",
              "       -1.20911151e-01,  1.33074015e-01, -2.40076296e-02, -8.61709863e-02,\n",
              "       -1.79991545e-03,  3.91840525e-02, -3.06748301e-02, -1.10395163e-01,\n",
              "       -1.44113809e-01,  3.47533152e-02,  1.26442760e-01,  1.51098520e-01,\n",
              "       -1.47495106e-01,  9.89220962e-02,  1.07589796e-01,  9.38937441e-02,\n",
              "       -1.53009564e-01, -1.30068827e-02, -1.14716075e-01, -1.30422384e-01,\n",
              "        1.86000764e-02,  5.32120466e-05, -2.31985860e-02, -1.07203282e-01,\n",
              "       -3.31636667e-02,  4.47869375e-02,  2.25304645e-02,  1.85147613e-01,\n",
              "        5.13294712e-03, -1.23191781e-01,  8.12826157e-02, -8.51961747e-02,\n",
              "       -9.72918421e-02, -1.90278441e-02, -6.44630939e-02, -1.08691052e-01,\n",
              "        2.70893425e-02,  1.02976874e-01,  1.80976331e-01, -1.63971558e-02,\n",
              "       -7.17620775e-02, -7.96736404e-02, -9.61826518e-02, -1.91508874e-01,\n",
              "        2.70473287e-02,  1.24248281e-01, -3.49661916e-01, -1.33518144e-01,\n",
              "       -2.82961894e-02, -9.26014706e-02, -4.25025821e-04, -2.86594480e-02,\n",
              "       -3.91338617e-02, -9.90596265e-02, -4.65282984e-02, -8.72748494e-02,\n",
              "        1.51935905e-01, -1.91162080e-02,  9.13072601e-02,  1.89611129e-02,\n",
              "       -1.08969875e-01, -2.90214196e-02,  8.61809775e-02, -2.18289584e-01,\n",
              "       -1.40584171e-01, -2.89806034e-02,  8.69408399e-02,  1.18448846e-02,\n",
              "        9.80549902e-02,  5.18676490e-02, -3.34505178e-03,  8.01285952e-02,\n",
              "        6.87225088e-02,  1.70012593e-01,  3.26067172e-02,  1.63739957e-02,\n",
              "        3.87846790e-02, -1.26889497e-02, -3.26282345e-02,  9.15853605e-02,\n",
              "        5.58803044e-03,  1.06696427e-01, -4.73687798e-02, -1.07843116e-01,\n",
              "       -8.31641108e-02,  1.36591256e-01,  2.29387909e-01, -2.46172547e-02,\n",
              "        2.01673638e-02, -2.14638207e-02, -1.00305840e-01,  1.96577206e-01,\n",
              "        1.44458741e-01,  9.78642032e-02,  1.25113457e-01, -5.35797067e-02,\n",
              "       -6.95556924e-02, -1.35392934e-01,  3.14381532e-02,  1.78394511e-01,\n",
              "        5.15805036e-02,  3.73208970e-02,  1.08873099e-01,  5.15858382e-02,\n",
              "        3.36884856e-02,  9.44927931e-02,  9.98455137e-02, -5.56635223e-02,\n",
              "       -1.62284330e-01,  2.38388091e-01,  8.31078738e-03, -7.34476894e-02,\n",
              "       -1.08296201e-01,  6.40900210e-02, -1.30532300e-02,  1.64562717e-01,\n",
              "        5.02874181e-02, -1.77713811e-01, -4.69116122e-03, -2.90708076e-02,\n",
              "        1.00689061e-01,  1.28326267e-01, -1.63036004e-01,  1.28823876e-01,\n",
              "       -4.02787179e-02, -1.83677584e-01,  7.98890889e-02, -4.12471667e-02,\n",
              "       -3.48612294e-02, -6.26894534e-02, -1.59047395e-01,  1.87391803e-01,\n",
              "        3.71768177e-02,  2.79565807e-02,  1.63159668e-01,  3.75718437e-02,\n",
              "        7.86873326e-02, -2.44909581e-02, -6.72861934e-02, -3.14295776e-02,\n",
              "        1.51372068e-02, -5.56141920e-02,  4.48027030e-02, -1.93316251e-01,\n",
              "        2.06538424e-01, -8.87603462e-02, -9.88327265e-02,  2.40609385e-02,\n",
              "       -1.47456363e-01,  8.88570175e-02, -9.27246436e-02, -9.50970054e-02,\n",
              "        1.18448839e-01,  3.29303920e-01,  1.54580414e-01,  1.43435687e-01,\n",
              "       -1.28814936e-01,  7.68910497e-02,  3.72115988e-03,  1.75254852e-01,\n",
              "       -8.40665251e-02, -2.76442617e-02, -5.33436462e-02,  7.45012611e-02,\n",
              "       -5.63166961e-02, -9.66539606e-04,  1.13127068e-01,  2.83497237e-02,\n",
              "        5.91475405e-02, -7.03010559e-02, -4.37492207e-02,  5.44570349e-02,\n",
              "       -2.06605077e-01,  3.03150155e-02, -1.34049416e-01, -3.00040841e-02,\n",
              "       -2.13847756e-02,  5.49306124e-02, -1.04515314e-01, -4.16764542e-02,\n",
              "       -5.24726398e-02, -5.46058267e-02, -1.92172214e-01, -2.53393352e-01,\n",
              "        1.28208563e-01, -3.39920893e-02,  5.07736392e-02,  3.05913612e-02,\n",
              "       -9.96698514e-02, -5.63710779e-02,  4.16795760e-02,  8.36478733e-03,\n",
              "       -1.09555885e-01,  4.91313301e-02,  3.91997732e-02,  2.97623277e-02,\n",
              "       -5.84195256e-02,  2.64039308e-01,  1.03534430e-01,  2.85770763e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "ft_model['man']  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7cqE-3XfAM9"
      },
      "source": [
        "Now we can test a bit the capabilities of fastText (examples are taken from [here](https://fasttext.cc/docs/en/unsupervised-tutorial.html))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdNL7kcTlIzH"
      },
      "source": [
        "A base functionality is to search for close vectors in the embedding space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "85EKLO7FfAXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3df06b-5ae3-4bfd-d6e3-b92b91cdb28c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7746413350105286, 'aspargus'),\n",
              " (0.7368614077568054, 'Asparagus'),\n",
              " (0.7233701944351196, 'broccoli'),\n",
              " (0.7113494873046875, 'broccolini'),\n",
              " (0.7106742262840271, 'leeks'),\n",
              " (0.7096290588378906, 'artichokes'),\n",
              " (0.7028921842575073, 'asparagas'),\n",
              " (0.6759673953056335, 'kohlrabi'),\n",
              " (0.6757089495658875, 'radishes'),\n",
              " (0.6669561862945557, 'spinach')]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "word = 'asparagus'\n",
        "\n",
        "ft_model.get_nearest_neighbors(word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nlZYw5_4-9U"
      },
      "source": [
        "The first search takes additional time because the model is doing some sort of indexing in the embedding space. fastText uses a tool called FAISS to speed up the search in the embedding space (https://github.com/facebookresearch/faiss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8t5WUH-fJSQ"
      },
      "source": [
        "We can also solve analogies directly, without doing the computations by hand"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXrLJK8jfJbN",
        "outputId": "33cb1b4c-20b5-47c6-94c3-634c55db87be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7647636532783508, 'snes'),\n",
              " (0.7282403707504272, 'gamecube'),\n",
              " (0.7111096382141113, 'n64'),\n",
              " (0.6962550282478333, 'gba'),\n",
              " (0.6485379338264465, 'dreamcast'),\n",
              " (0.6467888951301575, 'ps2'),\n",
              " (0.6442886590957642, 'SNES'),\n",
              " (0.6383660435676575, 'zelda'),\n",
              " (0.6379032135009766, 'Snes'),\n",
              " (0.6377424001693726, 'famicom')]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# ft_model.get_analogies(\"man\", \"woman\", \"king\")\n",
        "ft_model.get_analogies(\"psx\", \"sony\", \"nintendo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAEZQAPNmjTv"
      },
      "source": [
        "Note that we are dealing with a model using also subword n-grams, so we can get the representation and the similarity even of out of vocabulary words\n",
        "\n",
        "For example we can search for the word **confuzzling** (which is an actual real fake word https://en.wiktionary.org/wiki/confuzzling):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIkjsmJvn-Ce",
        "outputId": "f5fccc4f-d685-4020-a5c5-4c2187ecd7a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word confuzzling is in the fastText model vocabulary? False\n",
            "0.613641083240509: confuzzled\n",
            "0.550931990146637: Confuzzled\n",
            "0.4055270850658417: confuddled\n",
            "0.3816613256931305: confusing\n",
            "0.36328595876693726: confused\n",
            "0.36032891273498535: nondescriptive\n",
            "0.359388530254364: Wikipedia-Page-Suzannah-B-Troy-6-yrs-after-Misogynist-Cyber-Vandalism-Censorship-via-Deletion-on-a-page-about-Censorship-Wikipedia-Agrees-to-retur\n",
            "0.3525550067424774: muddly\n",
            "0.3524904251098633: official-like\n",
            "0.3516576588153839: unflattering.Coordinating\n"
          ]
        }
      ],
      "source": [
        "word = \"confuzzling\"\n",
        "print(f'Word {word} is in the fastText model vocabulary? {word in ft_model}')\n",
        "for s, w in ft_model.get_nearest_neighbors(word):\n",
        "    print(f'{s}: {w}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2pV3BOHoAn4"
      },
      "source": [
        "This is why character n-grams are so important"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX-XKdrB4-9X"
      },
      "source": [
        "We can also encode a sentence (sequence of tokens) into a single vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d0FyLCH4-9X",
        "outputId": "f2573c3d-2372-4da5-a13b-348abfa06e47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 9.72567871e-03, -1.81693081e-02,  1.98467262e-02,  3.74992117e-02,\n",
              "       -3.59138474e-02, -4.57771569e-02, -2.72532683e-02,  1.52418101e-02,\n",
              "        3.52445617e-02, -7.53624178e-03,  9.12996754e-03, -2.10552160e-02,\n",
              "        1.56272377e-03, -9.82039783e-05, -8.77684914e-03,  3.65382321e-02,\n",
              "        3.64734158e-02, -7.05009839e-03, -2.33118087e-02,  6.08711829e-03,\n",
              "       -1.99545734e-02,  1.54522238e-02,  6.07244065e-03, -8.34608357e-03,\n",
              "       -3.15462463e-02, -9.89805069e-03, -5.55238919e-04, -6.88232016e-03,\n",
              "       -1.15120355e-02,  1.13332726e-01,  2.06005611e-02, -1.42829418e-02,\n",
              "       -4.10122750e-03, -1.72664113e-02,  3.63585819e-03, -1.34615647e-02,\n",
              "       -4.80954209e-03,  4.18015793e-02, -8.03579669e-03, -5.55655640e-03,\n",
              "       -3.50303599e-03,  5.23055904e-03, -2.29117647e-02,  2.92630084e-02,\n",
              "        2.04842985e-02,  3.14234160e-02,  2.69671367e-03,  4.90053743e-02,\n",
              "        1.12765245e-02,  4.62619215e-03,  5.81054529e-03, -1.93861313e-02,\n",
              "        2.83782464e-03, -1.67906247e-02, -2.73843724e-02, -1.90940611e-02,\n",
              "       -2.87314001e-02, -2.75015947e-03, -6.57397807e-02, -6.99969940e-03,\n",
              "        1.24857184e-02, -8.20487388e-04, -1.48562761e-02, -2.38044374e-02,\n",
              "       -1.55957444e-02,  6.65766560e-03,  1.01082725e-02, -2.63807271e-02,\n",
              "        5.37982397e-03, -1.97686311e-02, -1.71130747e-02, -1.01001766e-02,\n",
              "       -1.09787043e-02, -1.05317784e-02, -9.84023418e-03, -8.84000864e-03,\n",
              "        2.20294278e-02,  1.01807080e-02, -2.01867130e-02, -1.07014319e-02,\n",
              "       -2.30140449e-03, -1.70639548e-02, -6.14872994e-03,  3.77793796e-02,\n",
              "       -1.51983332e-02,  8.82430526e-04,  1.63081381e-02,  3.15420181e-02,\n",
              "        3.46342996e-02, -2.07642070e-03, -1.01455227e-02, -2.21963469e-02,\n",
              "        1.20085992e-01, -2.47170683e-02, -3.93651379e-03,  1.47843389e-02,\n",
              "       -2.19641663e-02,  3.33386399e-02,  6.30210200e-03, -5.31568774e-04,\n",
              "        9.85516049e-03,  1.57738347e-02,  2.45013870e-02, -5.04032895e-02,\n",
              "       -2.86772917e-03,  3.74312233e-03,  5.90666989e-03, -1.19731538e-02,\n",
              "       -9.51060839e-03,  3.18147354e-02, -4.23025386e-03, -2.50816215e-02,\n",
              "       -4.44951048e-03,  5.48362173e-02, -5.97885251e-03,  3.35490418e-04,\n",
              "        5.40257385e-03,  1.93157159e-02,  9.49823856e-03,  9.22990963e-03,\n",
              "       -6.44654315e-03,  1.84089541e-02,  6.97864406e-03, -9.98760853e-03,\n",
              "        2.60523483e-02,  3.91055793e-02, -1.44942291e-02, -3.06311846e-02,\n",
              "       -1.64818224e-02,  2.83545423e-02,  6.74407184e-03, -3.35399993e-02,\n",
              "        4.63601090e-02,  1.43400459e-02,  1.51103102e-02, -3.57168838e-02,\n",
              "       -7.21709505e-02,  9.89099871e-03,  1.72942702e-04,  1.05020022e-02,\n",
              "       -2.54397653e-02, -2.65723094e-03,  7.78966863e-03,  3.41638178e-03,\n",
              "        2.90719923e-02,  2.88213808e-02, -2.04293147e-01, -7.63232820e-03,\n",
              "        4.07393230e-03,  2.32063141e-03, -5.25560267e-02, -2.20788294e-03,\n",
              "        1.10511016e-02,  3.85448784e-02, -7.09905615e-03, -1.07400753e-02,\n",
              "        6.98973909e-02,  9.88921523e-03,  1.12778405e-02,  6.80889981e-03,\n",
              "       -4.44709882e-03,  1.29796355e-03, -1.72076363e-03, -5.56946965e-03,\n",
              "        5.87231293e-03,  6.33573765e-03,  2.31747981e-02, -7.90966395e-03,\n",
              "        1.42229358e-02,  1.28066996e-02,  6.79592090e-03,  2.46544043e-03,\n",
              "       -1.16840629e-02,  6.73506968e-03,  1.11606503e-02, -2.94231921e-02,\n",
              "       -4.80693625e-03, -3.77772190e-02,  2.07332522e-02, -1.08723072e-02,\n",
              "        1.20459739e-02,  2.76545398e-02, -7.18570314e-03,  2.37664431e-02,\n",
              "        1.52243748e-02,  1.62549820e-02, -5.45680337e-03, -1.56360455e-02,\n",
              "        1.35150431e-02, -1.02946321e-02, -3.60844545e-02, -5.81913395e-03,\n",
              "       -2.99452688e-04, -1.34269800e-02, -1.33235017e-02,  4.67933854e-03,\n",
              "       -5.23591042e-03, -7.61942146e-03,  1.55100925e-02,  4.34672050e-02,\n",
              "       -3.93452123e-02,  7.63231665e-02, -5.74396225e-03, -2.23684981e-02,\n",
              "       -9.29937419e-03,  1.39698514e-03, -2.73167957e-02, -3.16865183e-02,\n",
              "        9.01725609e-03, -1.52197666e-02,  2.87998165e-03, -6.78938907e-03,\n",
              "       -1.75043494e-02,  8.25327064e-04,  5.83430799e-03, -1.03405640e-02,\n",
              "        1.68033578e-02,  1.82143655e-02,  2.17762217e-02, -3.85117112e-03,\n",
              "        1.55988140e-02,  3.93333882e-02, -1.15634808e-02,  1.36978207e-02,\n",
              "       -1.20003102e-02, -3.80420797e-02,  1.70185268e-02, -1.69083364e-02,\n",
              "       -4.47914330e-03,  1.10276509e-03, -6.27888803e-05,  5.13450429e-03,\n",
              "       -2.36676801e-02,  1.75183604e-03, -5.80153009e-03, -4.86875996e-02,\n",
              "       -2.43026740e-03, -5.56256901e-03,  1.50256902e-02, -9.55843367e-03,\n",
              "        2.34674127e-03,  1.41580636e-02, -7.86390621e-03, -7.69271106e-02,\n",
              "        2.54464388e-01, -1.19995847e-02, -3.09936162e-02,  2.66964808e-02,\n",
              "        1.56647675e-02, -5.45657892e-03,  3.70361917e-02, -1.24057243e-03,\n",
              "       -1.31606916e-02, -3.42799649e-02, -3.24210990e-03, -7.40021467e-03,\n",
              "       -3.67991813e-03, -2.00018543e-03,  1.92347188e-02,  9.79715493e-03,\n",
              "        1.03291485e-03,  3.97863425e-02,  1.01542631e-02,  5.11851441e-03,\n",
              "       -1.80702619e-02, -4.18641046e-03,  1.49878440e-02,  5.19764423e-03,\n",
              "        9.14397370e-03, -6.96600154e-02, -7.67690083e-03, -3.66979875e-02,\n",
              "       -2.45904680e-02,  3.70250712e-03,  2.24400274e-02, -2.23757178e-02,\n",
              "        1.79715436e-02, -8.35847482e-03,  5.23335813e-03,  2.31429515e-03,\n",
              "       -1.48976902e-02, -1.14535531e-02, -1.33328527e-01, -2.64611933e-02,\n",
              "        1.99319292e-02, -7.68285769e-04,  9.32648126e-03, -7.84917027e-02,\n",
              "       -1.71542703e-03, -7.22914794e-03,  4.42805514e-02, -8.75132810e-06,\n",
              "       -8.98919031e-02,  9.89831518e-03, -2.02262457e-02, -1.59065821e-03,\n",
              "        2.72551887e-02,  1.09358311e-01, -3.25395651e-02, -3.00224405e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "sent = ft_model.get_sentence_vector(\"Hello, is it me you're looking for? I can see it in your eyes. I can see it in your smile.\")\n",
        "sent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVsaSV9D4-9X"
      },
      "source": [
        "(Maybe this can be useful to train a classifier for the twitter sentiment analysis...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DHBjjIL4-9Y"
      },
      "source": [
        "What if we want to train a model on our own (maybe with smaller embeddings)?\n",
        "You can find a quick reference to the API [here](https://fasttext.cc/docs/en/python-module.html)\n",
        "\n",
        "To train a model we need to convert the data set into the appropriate format, a text file containing al the samples we have.\n",
        "We can start from the sentences we have from before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "RIDwQwbG4-9Y"
      },
      "outputs": [],
      "source": [
        "with open('./data.txt', 'w') as f:\n",
        "    f.write('\\n'.join(sentences))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ume-tXue4-9Z"
      },
      "source": [
        "We can even choose whether to use a Skipgram based approach:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Krfs8AuN4-9a"
      },
      "outputs": [],
      "source": [
        "ft_skip_model = fasttext.train_unsupervised('data.txt', model='skipgram', dim=30, minCount=5, ws=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfStz7_R4-9a"
      },
      "source": [
        "Or a Continuos Bag-of-Words (CBoW) approach:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT6QdxUt4-9a"
      },
      "outputs": [],
      "source": [
        "ft_cbow_model = fasttext.train_unsupervised('data.txt', model='cbow')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4flYwyd4-9b"
      },
      "source": [
        "Try to do the same visualisation we tried before, see how the same words are placed in a downprojection of the representation space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIS622TC4-9b"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}